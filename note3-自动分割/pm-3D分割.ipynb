{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 训练模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copyright (c) MONAI Consortium\n",
    "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#     http://www.apache.org/licenses/LICENSE-2.0\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License.\n",
    "\n",
    "import logging\n",
    "import os\n",
    "os.environ['KMP_DUPLICATE_LIB_OK'] = 'True'\n",
    "import sys\n",
    "import tempfile\n",
    "from glob import glob\n",
    "\n",
    "import nibabel as nib\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "import monai\n",
    "from monai.data import create_test_image_3d, list_data_collate, decollate_batch\n",
    "from monai.inferers import sliding_window_inference\n",
    "from monai.metrics import DiceMetric\n",
    "from monai.transforms import (\n",
    "    Activations,\n",
    "    EnsureChannelFirstd,\n",
    "    AsDiscrete,\n",
    "    Compose,\n",
    "    LoadImaged,\n",
    "    RandCropByPosNegLabeld,\n",
    "    RandRotate90d,\n",
    "    ScaleIntensityd,\n",
    ")\n",
    "from monai.visualize import plot_2d_or_3d_image\n",
    "\n",
    "def main():\n",
    "    monai.config.print_config()\n",
    "    logging.basicConfig(stream=sys.stdout, level=logging.INFO)\n",
    "\n",
    "    images = sorted(glob(os.path.join(r'E:\\seg_data\\Task06_Lung\\imagesTr', \"*.nii.gz\")))\n",
    "    segs = sorted(glob(os.path.join(r'E:\\seg_data\\Task06_Lung\\labelsTr', \"*.nii.gz\")))\n",
    "    train_files = [{\"img\": img, \"seg\": seg} for img, seg in zip(images[:20], segs[:20])]\n",
    "    val_files = [{\"img\": img, \"seg\": seg} for img, seg in zip(images[-20:], segs[-20:])]\n",
    "    # define transforms for image and segmentation\n",
    "    train_transforms = Compose(\n",
    "        [\n",
    "            LoadImaged(keys=[\"img\", \"seg\"]),\n",
    "            EnsureChannelFirstd(keys=[\"img\", \"seg\"]),\n",
    "            ScaleIntensityd(keys=\"img\"),\n",
    "            RandCropByPosNegLabeld(\n",
    "                keys=[\"img\", \"seg\"], label_key=\"seg\", spatial_size=[96, 96, 96], pos=1, neg=1, num_samples=4\n",
    "            ),\n",
    "            RandRotate90d(keys=[\"img\", \"seg\"], prob=0.5, spatial_axes=[0, 2]),\n",
    "        ]\n",
    "    )\n",
    "    val_transforms = Compose(\n",
    "        [\n",
    "            LoadImaged(keys=[\"img\", \"seg\"]),\n",
    "            EnsureChannelFirstd(keys=[\"img\", \"seg\"]),\n",
    "            ScaleIntensityd(keys=\"img\"),\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    # define dataset, data loader\n",
    "    check_ds = monai.data.Dataset(data=train_files, transform=train_transforms)\n",
    "    # use batch_size=2 to load images and use RandCropByPosNegLabeld to generate 2 x 4 images for network training\n",
    "    check_loader = DataLoader(check_ds, batch_size=2, num_workers=4, collate_fn=list_data_collate)\n",
    "    check_data = monai.utils.misc.first(check_loader)\n",
    "    print(check_data[\"img\"].shape, check_data[\"seg\"].shape)\n",
    "\n",
    "    # create a training data loader\n",
    "    train_ds = monai.data.Dataset(data=train_files, transform=train_transforms)\n",
    "    # use batch_size=2 to load images and use RandCropByPosNegLabeld to generate 2 x 4 images for network training\n",
    "    train_loader = DataLoader(\n",
    "        train_ds,\n",
    "        batch_size=2,\n",
    "        shuffle=True,\n",
    "        num_workers=4,\n",
    "        collate_fn=list_data_collate,\n",
    "        pin_memory=torch.cuda.is_available(),\n",
    "    )\n",
    "    # create a validation data loader\n",
    "    val_ds = monai.data.Dataset(data=val_files, transform=val_transforms)\n",
    "    val_loader = DataLoader(val_ds, batch_size=1, num_workers=4, collate_fn=list_data_collate)\n",
    "    dice_metric = DiceMetric(include_background=True, reduction=\"mean\", get_not_nans=False)\n",
    "    post_trans = Compose([Activations(sigmoid=True), AsDiscrete(threshold=0.5)])\n",
    "    # create UNet, DiceLoss and Adam optimizer\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model = monai.networks.nets.UNETR(\n",
    "        spatial_dims=3,\n",
    "        in_channels=1,\n",
    "        out_channels=1,\n",
    "        img_size=[96,96,96]\n",
    "       # channels=(16, 32, 64, 128, 256),\n",
    "       # strides=(2, 2, 2, 2),\n",
    "       # num_res_units=2,\n",
    "    ).to(device)\n",
    "    loss_function = monai.losses.DiceLoss(sigmoid=True)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), 1e-3)\n",
    "\n",
    "    # start a typical PyTorch training\n",
    "    val_interval = 2\n",
    "    best_metric = -1\n",
    "    best_metric_epoch = -1\n",
    "    epoch_loss_values = list()\n",
    "    metric_values = list()\n",
    "    writer = SummaryWriter()\n",
    "    for epoch in range(5):\n",
    "        print(\"-\" * 10)\n",
    "        print(f\"epoch {epoch + 1}/{5}\")\n",
    "        model.train()\n",
    "        epoch_loss = 0\n",
    "        step = 0\n",
    "        for batch_data in train_loader:\n",
    "            step += 1\n",
    "            inputs, labels = batch_data[\"img\"].to(device), batch_data[\"seg\"].to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss = loss_function(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            epoch_loss += loss.item()\n",
    "            epoch_len = len(train_ds) // train_loader.batch_size\n",
    "            print(f\"{step}/{epoch_len}, train_loss: {loss.item():.4f}\")\n",
    "            writer.add_scalar(\"train_loss\", loss.item(), epoch_len * epoch + step)\n",
    "        epoch_loss /= step\n",
    "        epoch_loss_values.append(epoch_loss)\n",
    "        print(f\"epoch {epoch + 1} average loss: {epoch_loss:.4f}\")\n",
    "\n",
    "        if (epoch + 1) % val_interval == 0:\n",
    "            model.eval()\n",
    "            with torch.no_grad():\n",
    "                val_images = None\n",
    "                val_labels = None\n",
    "                val_outputs = None\n",
    "                for val_data in val_loader:\n",
    "                    val_images, val_labels = val_data[\"img\"].to(device), val_data[\"seg\"].to(device)\n",
    "                    roi_size = (96, 96, 96)\n",
    "                    sw_batch_size = 4\n",
    "                    val_outputs = sliding_window_inference(val_images, roi_size, sw_batch_size, model)\n",
    "                    val_outputs = [post_trans(i) for i in decollate_batch(val_outputs)]\n",
    "                    # compute metric for current iteration\n",
    "                    dice_metric(y_pred=val_outputs, y=val_labels)\n",
    "                # aggregate the final mean dice result\n",
    "                metric = dice_metric.aggregate().item()\n",
    "                # reset the status for next validation round\n",
    "                dice_metric.reset()\n",
    "\n",
    "                metric_values.append(metric)\n",
    "                if metric > best_metric:\n",
    "                    best_metric = metric\n",
    "                    best_metric_epoch = epoch + 1\n",
    "                    torch.save(model.state_dict(), \"best_metric_model_segmentation3d_dict.pth\")\n",
    "                    print(\"saved new best metric model\")\n",
    "                print(\n",
    "                    \"current epoch: {} current mean dice: {:.4f} best mean dice: {:.4f} at epoch {}\".format(\n",
    "                        epoch + 1, metric, best_metric, best_metric_epoch\n",
    "                    )\n",
    "                )\n",
    "                writer.add_scalar(\"val_mean_dice\", metric, epoch + 1)\n",
    "                # plot the last model output as GIF image in TensorBoard with the corresponding image and label\n",
    "                plot_2d_or_3d_image(val_images, epoch + 1, writer, index=0, tag=\"image\")\n",
    "                plot_2d_or_3d_image(val_labels, epoch + 1, writer, index=0, tag=\"label\")\n",
    "                plot_2d_or_3d_image(val_outputs, epoch + 1, writer, index=0, tag=\"output\")\n",
    "\n",
    "    print(f\"train completed, best_metric: {best_metric:.4f} at epoch: {best_metric_epoch}\")\n",
    "    writer.close()\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "        main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 推理模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MONAI version: 1.1.0\n",
      "Numpy version: 1.24.4\n",
      "Pytorch version: 2.0.0+cu118\n",
      "MONAI flags: HAS_EXT = False, USE_COMPILED = False, USE_META_DICT = False\n",
      "MONAI rev id: a2ec3752f54bfc3b40e7952234fbeb5452ed63e3\n",
      "MONAI __file__: d:\\pixelmedAI\\envs\\pixelmed38\\lib\\site-packages\\monai\\__init__.py\n",
      "\n",
      "Optional dependencies:\n",
      "Pytorch Ignite version: NOT INSTALLED or UNKNOWN VERSION.\n",
      "Nibabel version: 5.2.1\n",
      "scikit-image version: 0.21.0\n",
      "Pillow version: 10.2.0\n",
      "Tensorboard version: 2.14.0\n",
      "gdown version: 5.2.0\n",
      "TorchVision version: 0.15.1+cu118\n",
      "tqdm version: 4.66.4\n",
      "lmdb version: NOT INSTALLED or UNKNOWN VERSION.\n",
      "psutil version: 5.9.8\n",
      "pandas version: 2.0.3\n",
      "einops version: 0.8.0\n",
      "transformers version: NOT INSTALLED or UNKNOWN VERSION.\n",
      "mlflow version: NOT INSTALLED or UNKNOWN VERSION.\n",
      "pynrrd version: 1.0.0\n",
      "\n",
      "For details about installing the optional dependencies, please visit:\n",
      "    https://docs.monai.io/en/latest/installation.html#installing-the-recommended-dependencies\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-08-01 20:11:05,913 INFO image_writer.py:194 - writing: out\\lung_001\\lung_001_seg.nii.gz\n",
      "2024-08-01 20:11:07,328 INFO image_writer.py:194 - writing: out\\lung_003\\lung_003_seg.nii.gz\n",
      "2024-08-01 20:11:08,788 INFO image_writer.py:194 - writing: out\\lung_004\\lung_004_seg.nii.gz\n",
      "2024-08-01 20:11:10,309 INFO image_writer.py:194 - writing: out\\lung_005\\lung_005_seg.nii.gz\n",
      "2024-08-01 20:11:11,826 INFO image_writer.py:194 - writing: out\\lung_006\\lung_006_seg.nii.gz\n",
      "2024-08-01 20:11:14,076 INFO image_writer.py:194 - writing: out\\lung_009\\lung_009_seg.nii.gz\n",
      "2024-08-01 20:11:15,471 INFO image_writer.py:194 - writing: out\\lung_010\\lung_010_seg.nii.gz\n",
      "2024-08-01 20:11:16,592 INFO image_writer.py:194 - writing: out\\lung_014\\lung_014_seg.nii.gz\n",
      "2024-08-01 20:11:18,982 INFO image_writer.py:194 - writing: out\\lung_015\\lung_015_seg.nii.gz\n",
      "2024-08-01 20:11:20,235 INFO image_writer.py:194 - writing: out\\lung_016\\lung_016_seg.nii.gz\n",
      "2024-08-01 20:11:21,174 INFO image_writer.py:194 - writing: out\\lung_018\\lung_018_seg.nii.gz\n",
      "2024-08-01 20:11:22,335 INFO image_writer.py:194 - writing: out\\lung_020\\lung_020_seg.nii.gz\n",
      "2024-08-01 20:11:23,924 INFO image_writer.py:194 - writing: out\\lung_022\\lung_022_seg.nii.gz\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 102\u001b[0m\n\u001b[0;32m    100\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    101\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m tempfile\u001b[38;5;241m.\u001b[39mTemporaryDirectory() \u001b[38;5;28;01mas\u001b[39;00m tempdir:\n\u001b[1;32m--> 102\u001b[0m         \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtempdir\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[1], line 97\u001b[0m, in \u001b[0;36mmain\u001b[1;34m(tempdir)\u001b[0m\n\u001b[0;32m     95\u001b[0m d[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpred\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m sliding_window_inference(inputs\u001b[38;5;241m=\u001b[39mimages, roi_size\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m96\u001b[39m, \u001b[38;5;241m96\u001b[39m, \u001b[38;5;241m96\u001b[39m), sw_batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m4\u001b[39m, predictor\u001b[38;5;241m=\u001b[39mnet)\n\u001b[0;32m     96\u001b[0m \u001b[38;5;66;03m# decollate the batch data into a list of dictionaries, then execute postprocessing transforms\u001b[39;00m\n\u001b[1;32m---> 97\u001b[0m d \u001b[38;5;241m=\u001b[39m [post_transforms(i) \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m decollate_batch(d)]\n",
      "Cell \u001b[1;32mIn[1], line 97\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     95\u001b[0m d[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpred\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m sliding_window_inference(inputs\u001b[38;5;241m=\u001b[39mimages, roi_size\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m96\u001b[39m, \u001b[38;5;241m96\u001b[39m, \u001b[38;5;241m96\u001b[39m), sw_batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m4\u001b[39m, predictor\u001b[38;5;241m=\u001b[39mnet)\n\u001b[0;32m     96\u001b[0m \u001b[38;5;66;03m# decollate the batch data into a list of dictionaries, then execute postprocessing transforms\u001b[39;00m\n\u001b[1;32m---> 97\u001b[0m d \u001b[38;5;241m=\u001b[39m [\u001b[43mpost_transforms\u001b[49m\u001b[43m(\u001b[49m\u001b[43mi\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m decollate_batch(d)]\n",
      "File \u001b[1;32md:\\pixelmedAI\\envs\\pixelmed38\\lib\\site-packages\\monai\\transforms\\compose.py:174\u001b[0m, in \u001b[0;36mCompose.__call__\u001b[1;34m(self, input_)\u001b[0m\n\u001b[0;32m    172\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, input_):\n\u001b[0;32m    173\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m _transform \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransforms:\n\u001b[1;32m--> 174\u001b[0m         input_ \u001b[38;5;241m=\u001b[39m \u001b[43mapply_transform\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_transform\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmap_items\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43munpack_items\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlog_stats\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    175\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m input_\n",
      "File \u001b[1;32md:\\pixelmedAI\\envs\\pixelmed38\\lib\\site-packages\\monai\\transforms\\transform.py:102\u001b[0m, in \u001b[0;36mapply_transform\u001b[1;34m(transform, data, map_items, unpack_items, log_stats)\u001b[0m\n\u001b[0;32m    100\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, (\u001b[38;5;28mlist\u001b[39m, \u001b[38;5;28mtuple\u001b[39m)) \u001b[38;5;129;01mand\u001b[39;00m map_items:\n\u001b[0;32m    101\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m [_apply_transform(transform, item, unpack_items) \u001b[38;5;28;01mfor\u001b[39;00m item \u001b[38;5;129;01min\u001b[39;00m data]\n\u001b[1;32m--> 102\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_apply_transform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtransform\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43munpack_items\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    103\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    104\u001b[0m     \u001b[38;5;66;03m# if in debug mode, don't swallow exception so that the breakpoint\u001b[39;00m\n\u001b[0;32m    105\u001b[0m     \u001b[38;5;66;03m# appears where the exception was raised.\u001b[39;00m\n\u001b[0;32m    106\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m MONAIEnvVars\u001b[38;5;241m.\u001b[39mdebug():\n",
      "File \u001b[1;32md:\\pixelmedAI\\envs\\pixelmed38\\lib\\site-packages\\monai\\transforms\\transform.py:66\u001b[0m, in \u001b[0;36m_apply_transform\u001b[1;34m(transform, parameters, unpack_parameters)\u001b[0m\n\u001b[0;32m     63\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(parameters, \u001b[38;5;28mtuple\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m unpack_parameters:\n\u001b[0;32m     64\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m transform(\u001b[38;5;241m*\u001b[39mparameters)\n\u001b[1;32m---> 66\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtransform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\pixelmedAI\\envs\\pixelmed38\\lib\\site-packages\\monai\\transforms\\io\\dictionary.py:295\u001b[0m, in \u001b[0;36mSaveImaged.__call__\u001b[1;34m(self, data)\u001b[0m\n\u001b[0;32m    293\u001b[0m         meta_key \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkey\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmeta_key_postfix\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    294\u001b[0m     meta_data \u001b[38;5;241m=\u001b[39m d\u001b[38;5;241m.\u001b[39mget(meta_key) \u001b[38;5;28;01mif\u001b[39;00m meta_key \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m--> 295\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msaver\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43md\u001b[49m\u001b[43m[\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmeta_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmeta_data\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    296\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m d\n",
      "File \u001b[1;32md:\\pixelmedAI\\envs\\pixelmed38\\lib\\site-packages\\monai\\transforms\\io\\array.py:446\u001b[0m, in \u001b[0;36mSaveImage.__call__\u001b[1;34m(self, img, meta_data)\u001b[0m\n\u001b[0;32m    444\u001b[0m     writer_obj\u001b[38;5;241m.\u001b[39mset_data_array(data_array\u001b[38;5;241m=\u001b[39mimg, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata_kwargs)\n\u001b[0;32m    445\u001b[0m     writer_obj\u001b[38;5;241m.\u001b[39mset_metadata(meta_dict\u001b[38;5;241m=\u001b[39mmeta_data, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmeta_kwargs)\n\u001b[1;32m--> 446\u001b[0m     \u001b[43mwriter_obj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwrite\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwrite_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    447\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwriter_obj \u001b[38;5;241m=\u001b[39m writer_obj\n\u001b[0;32m    448\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[1;32md:\\pixelmedAI\\envs\\pixelmed38\\lib\\site-packages\\monai\\data\\image_writer.py:625\u001b[0m, in \u001b[0;36mNibabelWriter.write\u001b[1;34m(self, filename, verbose, **obj_kwargs)\u001b[0m\n\u001b[0;32m    623\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata_obj\u001b[38;5;241m.\u001b[39mset_sform(_affine, code\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m    624\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata_obj\u001b[38;5;241m.\u001b[39mset_qform(_affine, code\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m--> 625\u001b[0m \u001b[43mnib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msave\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdata_obj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\pixelmedAI\\envs\\pixelmed38\\lib\\site-packages\\nibabel\\loadsave.py:163\u001b[0m, in \u001b[0;36msave\u001b[1;34m(img, filename, **kwargs)\u001b[0m\n\u001b[0;32m    161\u001b[0m \u001b[38;5;66;03m# Save the type as expected\u001b[39;00m\n\u001b[0;32m    162\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 163\u001b[0m     \u001b[43mimg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_filename\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    164\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m ImageFileError:\n\u001b[0;32m    165\u001b[0m     \u001b[38;5;28;01mpass\u001b[39;00m\n",
      "File \u001b[1;32md:\\pixelmedAI\\envs\\pixelmed38\\lib\\site-packages\\nibabel\\filebasedimages.py:307\u001b[0m, in \u001b[0;36mFileBasedImage.to_filename\u001b[1;34m(self, filename, **kwargs)\u001b[0m\n\u001b[0;32m    291\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Write image to files implied by filename string\u001b[39;00m\n\u001b[0;32m    292\u001b[0m \n\u001b[0;32m    293\u001b[0m \u001b[38;5;124;03mParameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    304\u001b[0m \u001b[38;5;124;03mNone\u001b[39;00m\n\u001b[0;32m    305\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    306\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfile_map \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfilespec_to_file_map(filename)\n\u001b[1;32m--> 307\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_file_map\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\pixelmedAI\\envs\\pixelmed38\\lib\\site-packages\\nibabel\\nifti1.py:2217\u001b[0m, in \u001b[0;36mNifti1Pair.to_file_map\u001b[1;34m(self, file_map, dtype)\u001b[0m\n\u001b[0;32m   2215\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_data_dtype(finalize\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m   2216\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 2217\u001b[0m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_file_map\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile_map\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2218\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m   2219\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mset_data_dtype(img_dtype)\n",
      "File \u001b[1;32md:\\pixelmedAI\\envs\\pixelmed38\\lib\\site-packages\\nibabel\\analyze.py:1051\u001b[0m, in \u001b[0;36mAnalyzeImage.to_file_map\u001b[1;34m(self, file_map, dtype)\u001b[0m\n\u001b[0;32m   1049\u001b[0m seek_tell(imgf, hdr\u001b[38;5;241m.\u001b[39mget_data_offset(), write0\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m   1050\u001b[0m \u001b[38;5;66;03m# Write array data\u001b[39;00m\n\u001b[1;32m-> 1051\u001b[0m \u001b[43marr_writer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_fileobj\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimgf\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1052\u001b[0m hdrf\u001b[38;5;241m.\u001b[39mclose_if_mine()\n\u001b[0;32m   1053\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m hdr_img_same:\n",
      "File \u001b[1;32md:\\pixelmedAI\\envs\\pixelmed38\\lib\\site-packages\\nibabel\\arraywriters.py:525\u001b[0m, in \u001b[0;36mSlopeInterArrayWriter.to_fileobj\u001b[1;34m(self, fileobj, order)\u001b[0m\n\u001b[0;32m    516\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Write array into `fileobj`\u001b[39;00m\n\u001b[0;32m    517\u001b[0m \n\u001b[0;32m    518\u001b[0m \u001b[38;5;124;03mParameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    522\u001b[0m \u001b[38;5;124;03m    order (Fortran or C) to which to write array\u001b[39;00m\n\u001b[0;32m    523\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    524\u001b[0m mn, mx \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_writing_range()\n\u001b[1;32m--> 525\u001b[0m \u001b[43marray_to_file\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    526\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_array\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    527\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfileobj\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    528\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_out_dtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    529\u001b[0m \u001b[43m    \u001b[49m\u001b[43moffset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    530\u001b[0m \u001b[43m    \u001b[49m\u001b[43mintercept\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minter\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    531\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdivslope\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mslope\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    532\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmn\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    533\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmx\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    534\u001b[0m \u001b[43m    \u001b[49m\u001b[43morder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43morder\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    535\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnan2zero\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_needs_nan2zero\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    536\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\pixelmedAI\\envs\\pixelmed38\\lib\\site-packages\\nibabel\\volumeutils.py:605\u001b[0m, in \u001b[0;36marray_to_file\u001b[1;34m(data, fileobj, out_dtype, offset, intercept, divslope, mn, mx, order, nan2zero)\u001b[0m\n\u001b[0;32m    603\u001b[0m     pre_clips \u001b[38;5;241m=\u001b[39m _dt_min_max(in_dtype, \u001b[38;5;241m*\u001b[39mpre_clips)\n\u001b[0;32m    604\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m null_scaling \u001b[38;5;129;01mand\u001b[39;00m np\u001b[38;5;241m.\u001b[39mcan_cast(in_dtype, out_dtype):\n\u001b[1;32m--> 605\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_write_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfileobj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mout_dtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43morder\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpre_clips\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpre_clips\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    606\u001b[0m \u001b[38;5;66;03m# Force upcasting for floats by making atleast_1d.\u001b[39;00m\n\u001b[0;32m    607\u001b[0m slope, inter \u001b[38;5;241m=\u001b[39m (np\u001b[38;5;241m.\u001b[39matleast_1d(v) \u001b[38;5;28;01mfor\u001b[39;00m v \u001b[38;5;129;01min\u001b[39;00m (divslope, intercept))\n",
      "File \u001b[1;32md:\\pixelmedAI\\envs\\pixelmed38\\lib\\site-packages\\nibabel\\volumeutils.py:784\u001b[0m, in \u001b[0;36m_write_data\u001b[1;34m(data, fileobj, out_dtype, order, in_cast, pre_clips, inter, slope, post_clips, nan_fill)\u001b[0m\n\u001b[0;32m    782\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m dslice\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;241m!=\u001b[39m out_dtype:\n\u001b[0;32m    783\u001b[0m     dslice \u001b[38;5;241m=\u001b[39m dslice\u001b[38;5;241m.\u001b[39mastype(out_dtype)\n\u001b[1;32m--> 784\u001b[0m \u001b[43mfileobj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwrite\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdslice\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtobytes\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\pixelmedAI\\envs\\pixelmed38\\lib\\site-packages\\nibabel\\openers.py:232\u001b[0m, in \u001b[0;36mOpener.write\u001b[1;34m(self, b)\u001b[0m\n\u001b[0;32m    231\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrite\u001b[39m(\u001b[38;5;28mself\u001b[39m, b: \u001b[38;5;28mbytes\u001b[39m, \u001b[38;5;241m/\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mint\u001b[39m \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 232\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfobj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwrite\u001b[49m\u001b[43m(\u001b[49m\u001b[43mb\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\pixelmedAI\\envs\\pixelmed38\\lib\\gzip.py:280\u001b[0m, in \u001b[0;36mGzipFile.write\u001b[1;34m(self, data)\u001b[0m\n\u001b[0;32m    277\u001b[0m     length \u001b[38;5;241m=\u001b[39m data\u001b[38;5;241m.\u001b[39mnbytes\n\u001b[0;32m    279\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m length \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m--> 280\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfileobj\u001b[38;5;241m.\u001b[39mwrite(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompress\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompress\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m    281\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msize \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m length\n\u001b[0;32m    282\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcrc \u001b[38;5;241m=\u001b[39m zlib\u001b[38;5;241m.\u001b[39mcrc32(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcrc)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Copyright (c) MONAI Consortium\n",
    "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#     http://www.apache.org/licenses/LICENSE-2.0\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License.\n",
    "import os\n",
    "os.environ['KMP_DUPLICATE_LIB_OK'] = 'True'\n",
    "import logging\n",
    "import os\n",
    "import sys\n",
    "import tempfile\n",
    "from glob import glob\n",
    "\n",
    "import nibabel as nib\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "from monai.config import print_config\n",
    "from monai.data import Dataset, DataLoader, create_test_image_3d, decollate_batch\n",
    "from monai.inferers import sliding_window_inference\n",
    "from monai.networks.nets import UNet\n",
    "from monai.transforms import (\n",
    "    Activationsd,\n",
    "    AsDiscreted,\n",
    "    Compose,\n",
    "    EnsureChannelFirstd,\n",
    "    Invertd,\n",
    "    LoadImaged,\n",
    "    Orientationd,\n",
    "    Resized,\n",
    "    SaveImaged,\n",
    "    ScaleIntensityd,\n",
    ")\n",
    "\n",
    "def main(tempdir):\n",
    "    print_config()\n",
    "    logging.basicConfig(stream=sys.stdout, level=logging.INFO)\n",
    "\n",
    "    images = sorted(glob(os.path.join(r'E:\\seg_data\\Task06_Lung\\imagesTr', \"*.nii.gz\")))\n",
    "    files = [{\"img\": img} for img in images]\n",
    "\n",
    "    # define pre transforms\n",
    "    pre_transforms = Compose(\n",
    "        [\n",
    "            LoadImaged(keys=\"img\"),\n",
    "            EnsureChannelFirstd(keys=\"img\"),\n",
    "            Orientationd(keys=\"img\", axcodes=\"RAS\"),\n",
    "            Resized(keys=\"img\", spatial_size=(96, 96, 96), mode=\"trilinear\", align_corners=True),\n",
    "            ScaleIntensityd(keys=\"img\"),\n",
    "        ]\n",
    "    )\n",
    "    # define dataset and dataloader\n",
    "    dataset = Dataset(data=files, transform=pre_transforms)\n",
    "    dataloader = DataLoader(dataset, batch_size=2, num_workers=4)\n",
    "    # define post transforms\n",
    "    post_transforms = Compose(\n",
    "        [\n",
    "            Activationsd(keys=\"pred\", sigmoid=True),\n",
    "            Invertd(\n",
    "                keys=\"pred\",  # invert the `pred` data field, also support multiple fields\n",
    "                transform=pre_transforms,\n",
    "                orig_keys=\"img\",  # get the previously applied pre_transforms information on the `img` data field,\n",
    "                # then invert `pred` based on this information. we can use same info\n",
    "                # for multiple fields, also support different orig_keys for different fields\n",
    "                nearest_interp=False,  # don't change the interpolation mode to \"nearest\" when inverting transforms\n",
    "                # to ensure a smooth output, then execute `AsDiscreted` transform\n",
    "                to_tensor=True,  # convert to PyTorch Tensor after inverting\n",
    "            ),\n",
    "            AsDiscreted(keys=\"pred\", threshold=0.5),\n",
    "            SaveImaged(keys=\"pred\", output_dir=\"./out\", output_postfix=\"seg\", resample=False),\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    net = UNet(\n",
    "        spatial_dims=3,\n",
    "        in_channels=1,\n",
    "        out_channels=1,\n",
    "        channels=(16, 32, 64, 128, 256),\n",
    "        strides=(2, 2, 2, 2),\n",
    "        num_res_units=2,\n",
    "    ).to(device)\n",
    "    net.load_state_dict(torch.load(\"best_metric_model_segmentation3d_dict.pth\"))\n",
    "\n",
    "    net.eval()\n",
    "    with torch.no_grad():\n",
    "        for d in dataloader:\n",
    "            images = d[\"img\"].to(device)\n",
    "            # define sliding window size and batch size for windows inference\n",
    "            d[\"pred\"] = sliding_window_inference(inputs=images, roi_size=(96, 96, 96), sw_batch_size=4, predictor=net)\n",
    "            # decollate the batch data into a list of dictionaries, then execute postprocessing transforms\n",
    "            d = [post_transforms(i) for i in decollate_batch(d)]\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    with tempfile.TemporaryDirectory() as tempdir:\n",
    "        main(tempdir)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pm38",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
