{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 导入数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "os.makedirs('results/img', exist_ok=True)\n",
    "os.makedirs('results/model_weight', exist_ok=True)\n",
    "os.makedirs('results/pred', exist_ok=True)\n",
    "inputfile = 'DL_radmico_imagenet.csv'\n",
    "labelfile='label_class1.csv'\n",
    "data_feature=pd.read_csv(inputfile)\n",
    "mean_values = data_feature.loc[:, data_feature.columns != 'ID'].mean()\n",
    "data_feature.fillna(mean_values, inplace=True)\n",
    "data_label=pd.read_csv(labelfile)\n",
    "merged_data = pd.merge(data_feature, data_label, on='ID')\n",
    "merged_data.columns = merged_data.columns.str.replace(r'[-(),]', '_', regex=True) \n",
    "merged_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "plt.rcParams['figure.dpi'] = 300\n",
    "category_counts = merged_data.columns[1:-2].map(lambda x: x.split('_')[-2]).value_counts()\n",
    "category_counts_percent = category_counts / category_counts.sum() * 100\n",
    "display('特征个数统计：',category_counts)\n",
    "# 设置Seaborn的风格\n",
    "sns.set(style=\"whitegrid\")\n",
    "# 创建一个颜色调色板\n",
    "colors = sns.color_palette('pastel')[0:len(category_counts_percent)]\n",
    "# 创建3D效果的饼图\n",
    "fig, ax = plt.subplots(figsize=(12, 12), subplot_kw=dict(aspect=\"equal\"))\n",
    "wedges, texts, autotexts = ax.pie(category_counts_percent, labels=category_counts_percent.index, autopct='%1.1f%%', startangle=140,\n",
    "                                  colors=colors, wedgeprops=dict(width=0.3, edgecolor='w'))\n",
    "# 添加阴影效果以增强立体感\n",
    "for wedge in wedges:\n",
    "    wedge.set_edgecolor('w')\n",
    "    wedge.set_linewidth(8)\n",
    "# 添加中心白色圆圈使其成为环形图\n",
    "centre_circle = plt.Circle((0, 0), 0.2, fc='white', edgecolor='w')\n",
    "fig.gca().add_artist(centre_circle)\n",
    "# 调整文字和自动文字的样式\n",
    "plt.setp(texts, size=15, weight=\"bold\")\n",
    "plt.setp(autotexts, size=10, weight=\"bold\", color=\"white\")\n",
    "# 设置标题\n",
    "#ax.set_title('特征大类所占比例', fontsize=16)\n",
    "# 显示图表\n",
    "plt.tight_layout()\n",
    "plt.savefig('results/img/特征大类所占比例.svg')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "数据集包含较多的异常值，使用稳键归一化（robust normalization）\n",
    "value_result = (value-Media)/(Q1-Q3)  \n",
    "Q1的位置 = 1 * （n + 1) / 4  \n",
    "Q3的位置 =  3 *（n + 1) / 4  \n",
    "n : 表示数据的个数。  \n",
    "media : 中位数  \n",
    "Q1 : 是第 1 个四分位数（第 25 个分位数）  \n",
    "Q3 : 第 3 个四分位数（第 75 个分位数） \n",
    "\n",
    "method='robust' 稳键归一化,standard（z值标准化）,minmax（最大最小值标准化）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pixelmed_calc.medical_imaging.RadiologyComponents.components1 import sel_standard_data\n",
    "#method='robust',standard,minmax\n",
    "merged_data = sel_standard_data(merged_data, merged_data.columns[1:-2],method='robust')\n",
    "merged_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## F检验筛选特征\n",
    "\n",
    "多组比较：F检验通常用于分析方差分析（ANOVA），它可以同时比较三个或更多的组别。而T检验通常用于两组数据的比较。 \n",
    " 方差齐性检验：在进行T检验之前，通常需要先检验数据的方差是否齐性。F检验可以直接用于检验方差是否相等，这是T检验无法做到的。  \n",
    " 控制类型I错误：在进行多重比较的情况下，T检验可能会增加犯类型I错误的风险。而F检验通过调整P值，可以更好地控制这一风险。  \n",
    " 更广泛的适用性：F检验不仅限于两样本均值的比较，它还适用于多个样本均值的比较，以及因子水平的比较。  \n",
    " 实验设计：F检验可以应用于完全随机设计、随机区组设计、拉丁方设计等多种实验设计，而T检验通常只适用于两组独立样本或配对样本。  \n",
    " 多重比较问题：当涉及到多个比较时，F检验可以通过调整方法（如Bonferroni校正）来控制整体错误率，而T检验在多重比较时可能需要更复杂的方法来控制错误率。  \n",
    " 统计功效：在某些情况下，F检验可能具有比T检验更高的统计功效，尤其是在样本量较大时。  \n",
    " 非正态分布数据：虽然T检验和F检验都假设数据正态分布，但在实际应用中，F检验对于数据分布的正态性要求可能稍微宽松一些。  \n",
    "\n",
    "\n",
    " method='f_test',t_test,chi2_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pixelmed_calc.medical_imaging.RadiologyComponents.components1 import select_significant_features\n",
    "\n",
    "significant_features_sel, feature_scores=select_significant_features(merged_data, label_column='label', columns=merged_data.columns[1:-2],significance_level=0.05,method='f_test')\n",
    "feature_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set(style=\"whitegrid\")\n",
    "# 使用Seaborn绘制小提琴图\n",
    "plt.figure(figsize=(15, 10))\n",
    "# 使用不同的调色板，并将x变量分配给hue，关闭图例显示\n",
    "sns.violinplot(x='Category', y='p_value', data=feature_scores, hue='Category', palette=\"coolwarm\", legend=False)\n",
    "# 添加水平网格线以提高图形的可读性\n",
    "plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "# 设置标题和坐标标签的字体大小和风格\n",
    "plt.title('P value distribution', fontsize=20, weight='bold')\n",
    "plt.xlabel('Feature Category', fontsize=18)\n",
    "plt.ylabel('p value', fontsize=18)\n",
    "# 调整x轴标签的字体大小并旋转\n",
    "plt.xticks(fontsize=14, rotation=45, weight='bold')\n",
    "# 调整y轴标签的字体大小\n",
    "plt.yticks(fontsize=14, weight='bold')\n",
    "# 移动图例的位置并调整字体大小（由于关闭了图例显示部分，不再需要）\n",
    "# plt.legend(title='特征大类', title_fontsize='13', loc='upper right', fontsize='11')\n",
    "# 添加紧凑布局以防止图形元素重叠\n",
    "plt.tight_layout()\n",
    "# 显示图表\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set(style=\"whitegrid\")\n",
    "# 使用 Seaborn 绘制箱线图\n",
    "plt.figure(figsize=(15, 10))\n",
    "# 使用不同的调色板，并将 x 变量分配给 hue，关闭图例显示\n",
    "sns.boxplot(hue='Category', y='p_value', data=feature_scores, palette=\"coolwarm\")\n",
    "# 添加水平网格线以提高图形的可读性\n",
    "plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "# 设置标题和坐标标签的字体大小和风格\n",
    "plt.title('P value distribution', fontsize=20, weight='bold')\n",
    "plt.xlabel('Feature Category', fontsize=18)\n",
    "plt.ylabel('p value', fontsize=18)\n",
    "\n",
    "# 调整 x 轴标签的字体大小并旋转\n",
    "plt.xticks(fontsize=14, rotation=45, weight='bold')\n",
    "# 调整 y 轴标签的字体大小\n",
    "plt.yticks(fontsize=14, weight='bold')\n",
    "# 添加紧凑布局以防止图形元素重叠\n",
    "plt.tight_layout()\n",
    "# 显示图表\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np  \n",
    "import pandas as pd  \n",
    "from pixelmed_calc.medical_imaging.RadiologyComponents.components1 import filter_highly_correlated_features\n",
    "\n",
    "final_significant_features, removed_features = filter_highly_correlated_features(merged_data, significant_features_sel,'pearson',correlation_threshold=0.9)  \n",
    "\n",
    "print(f\"最终筛选的特征数量: {len(final_significant_features)}\")  \n",
    "print(final_significant_features)  \n",
    "\n",
    "print(f\"移除的特征: {removed_features}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_sel=merged_data[list(final_significant_features)+['label','group']]\n",
    "data_sel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train=data_sel[data_sel['group']=='train'].drop(['group','label'],axis=1)\n",
    "y_train=data_sel[data_sel['group']=='train']['label']\n",
    "\n",
    "x_test=data_sel[data_sel['group']=='test'].drop(['group','label'],axis=1)\n",
    "y_test=data_sel[data_sel['group']=='test']['label']\n",
    "\n",
    "x_all=data_sel.drop(['group','label'],axis=1)\n",
    "y_all=data_sel['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.linear_model import Lasso\n",
    "from pixelmed_calc.medical_imaging.RadiologyComponents.components1 import find_best_alpha\n",
    "alphas = np.logspace(-6,2,50)\n",
    "best_alpha,scores_lasso,scores_std_lasso=find_best_alpha(x_train, y_train,alphas=alphas)\n",
    "\n",
    "lasso = Lasso(alpha=best_alpha)\n",
    "lasso.fit(x_train, y_train)\n",
    "# 输出系数\n",
    "lasso_coefs = lasso.coef_\n",
    "# 创建 DataFrame 显示特征名和对应的系数\n",
    "coef_df = pd.DataFrame({'feature': x_train.columns, 'coef': lasso_coefs})\n",
    "selected_features = coef_df[abs(coef_df['coef']) > 1e-4]\n",
    "# 创建 DataFrame 显示特征名和对应的系数\n",
    "print(f\"选择的特征:\\n{selected_features}\")\n",
    "lasso_sel_cloumn=selected_features['feature']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import numpy as np\n",
    "plt.rcParams['figure.dpi'] = 300\n",
    "# 设置不同的alpha值范围\n",
    "alpha_values = [0.0001,0.001,0.002,0.005,0.008,0.01,0.1,1,10,50,100]#alphas\n",
    "lasso = Lasso(max_iter=1000)\n",
    "coefs = []\n",
    "num_nonzero_coefs = []\n",
    "for a in alpha_values:\n",
    "    lasso.set_params(alpha=a)\n",
    "    lasso.fit(x_train, y_train)\n",
    "    coefs.append(lasso.coef_)\n",
    "    num_nonzero_coefs.append(np.sum(lasso.coef_ != 0))\n",
    "ax = plt.gca()\n",
    "ax.plot(alpha_values, coefs)\n",
    "ax.set_xscale('log')\n",
    "plt.axis('tight')\n",
    "plt.xlabel(f'Log({best_alpha:.3f})')\n",
    "plt.ylabel('Coefficients')\n",
    "plt.title('Lasso coefficients as a function of alpha')\n",
    "plt.axvline(x=best_alpha, linestyle='--', color='r')\n",
    "plt.grid(False)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "平均分数计算：在完成所有交叉验证迭代后，GridSearchCV会计算每个参数组合在所有测试集上的平均得分。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "plt.figure().set_size_inches(8, 6)\n",
    "plt.semilogx(alphas, scores_lasso)\n",
    "# 显示误差线，显示+/-标准。 分数错误\n",
    "std_error = scores_std_lasso / np.sqrt(10)\n",
    "plt.semilogx(alphas, scores_lasso + std_error, 'b--')\n",
    "plt.semilogx(alphas, scores_lasso - std_error, 'b--')\n",
    "# alpha = 0.2控制填充颜色的半透明性\n",
    "plt.fill_between(alphas, scores_lasso + std_error, scores_lasso - std_error, alpha=0.2)\n",
    "plt.axvline(x=best_alpha, linestyle='--', color='r')\n",
    "plt.ylabel('CV score +/- std error')\n",
    "plt.xlabel(f'alpha({best_alpha:.3f})')\n",
    "plt.axhline(np.max(scores_lasso), linestyle='--', color='.5')\n",
    "plt.xlim([alphas[0], alphas[-1]])\n",
    "plt.grid(False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train=x_train[lasso_sel_cloumn]\n",
    "x_test=x_test[lasso_sel_cloumn]\n",
    "x_all=x_all[lasso_sel_cloumn]\n",
    "x_train.to_csv('results/pred/x_train.csv',index=False) \n",
    "x_test.to_csv('results/pred/x_test.csv',index=False)\n",
    "y_train.to_csv('results/pred/y_train.csv',index=False)\n",
    "y_test.to_csv('results/pred/y_test.csv',index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier,ExtraTreesClassifier,AdaBoostClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from xgboost.sklearn import XGBClassifier\n",
    "from lightgbm.sklearn import LGBMClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "models = [('LR', LogisticRegression(random_state=0)),\n",
    "          ('NB',GaussianNB()),\n",
    "          ('linear_SVM', SVC(kernel='linear',class_weight='balanced',probability=True,max_iter=1000)),\n",
    "          ('poly_SVM',SVC(kernel='poly',class_weight='balanced',probability=True)),\n",
    "          ('sigmoid_SVM',SVC(kernel='sigmoid',class_weight='balanced',probability=True)),\n",
    "          ('rbf_SVM',SVC(kernel='rbf',class_weight='balanced',probability=True)),\n",
    "          ('DT', DecisionTreeClassifier(max_depth=3,\n",
    "                                                            min_samples_split=2, random_state=0)),\n",
    "          ('RF', RandomForestClassifier(n_estimators=10, max_depth=3,\n",
    "                                                            min_samples_split=2, random_state=0)),\n",
    "          ('ExtraTree', ExtraTreesClassifier(n_estimators=10, max_depth=3,\n",
    "                                                        min_samples_split=2, random_state=0)),\n",
    "          ('XGBoost', XGBClassifier(n_estimators=10, objective='binary:logistic', max_depth=3,\n",
    "                                              use_label_encoder=False, eval_metric='error')),\n",
    "          ('AdaBoost',AdaBoostClassifier(n_estimators=10, random_state=0)),\n",
    "          ('MLP',MLPClassifier(hidden_layer_sizes=(128, 64, 32), max_iter=200, solver='adam', random_state=42)),\n",
    "          ('GBM',GradientBoostingClassifier(n_estimators=10, random_state=0)),\n",
    "          ('LightGBM',LGBMClassifier(n_estimators=10, max_depth=-1, objective='binary',verbosity=-1))]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score, confusion_matrix, f1_score, precision_score, recall_score, roc_curve\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import logging\n",
    "logging.getLogger('LightGBM').setLevel(logging.ERROR)  # 仅输出错误信息\n",
    "import joblib\n",
    "from sklearn.utils import resample\n",
    "from pixelmed_calc.medical_imaging.RadiologyComponents.components1 import calculate_metrics_with_ci\n",
    "\n",
    "# 创建DataFrame存储结果\n",
    "results = pd.DataFrame(columns=['Dataset', 'Model', 'Threshold', 'ACC', 'AUC', 'Sensitivity', 'Specificity', 'NPV', 'PPV', 'F1'])\n",
    "ci_results = pd.DataFrame(columns=['Dataset', 'Model', 'ACC', 'AUC', 'Sensitivity', 'Specificity', 'NPV', 'PPV', 'F1'])\n",
    "\n",
    "proba_dict_train = {}\n",
    "proba_dict_test = {}\n",
    "\n",
    "train_ids = merged_data[merged_data['group'] == 'train']['ID'].values\n",
    "test_ids = merged_data[merged_data['group'] == 'test']['ID'].values\n",
    "\n",
    "# 训练和测试所有模型\n",
    "for name, model in models:\n",
    "    print(f\"Training {name}...\")\n",
    "    #model.fit(x_all[0:270], y_all[0:270])\n",
    "    model.fit(x_train, y_train)\n",
    "    joblib.dump(model, f\"results/model_weight/{name}.pkl\")\n",
    "    # 在训练集、验证集和测试集上分别找到最佳阈值\n",
    "    y_train_proba = model.predict_proba(x_train)[:, 1]\n",
    "\n",
    "    y_test_proba = model.predict_proba(x_test)[:, 1]\n",
    "\n",
    "    # 使用最佳阈值进行预测和计算指标\n",
    "   \n",
    "    train_metrics,train_ci = calculate_metrics_with_ci(np.array(y_train),  np.array(y_train_proba),n_bootstrap=100)\n",
    "    \n",
    "    test_metrics,test_ci = calculate_metrics_with_ci(np.array(y_test), np.array(y_test_proba),n_bootstrap=100)\n",
    "\n",
    "    proba_dict_train[name] = y_train_proba\n",
    "    proba_dict_test[name] = y_test_proba\n",
    "\n",
    "    train_output = pd.DataFrame({'ID': train_ids, 'proba': y_train_proba})\n",
    "    train_output.to_csv(f'results/pred/{name}_train_proba.csv', index=False)\n",
    "\n",
    "    test_output = pd.DataFrame({'ID': test_ids, 'proba': y_test_proba})\n",
    "    test_output.to_csv(f'results/pred/{name}_test_proba.csv', index=False)\n",
    "    \n",
    "    # 将结果保存到DataFrame中\n",
    "    for dataset, metrics, res_ci,true_labels, pred_proba in zip(['Train', 'Test'], \n",
    "                                                        [train_metrics, test_metrics], \n",
    "                                                         [train_ci, test_ci], \n",
    "                                                        [y_train,y_test],\n",
    "                                                        [y_train_proba, y_test_proba]):\n",
    "        result = {\n",
    "            'Dataset': dataset,\n",
    "            'Model': name,\n",
    "            'Threshold': metrics['threshold'],\n",
    "            'ACC': metrics['accuracy'],\n",
    "            'AUC': metrics['auc'],\n",
    "            'Sensitivity': metrics['sensitivity'],\n",
    "            'Specificity': metrics['specificity'],\n",
    "            'NPV': metrics['npv'],\n",
    "            'PPV': metrics['ppv'],\n",
    "            'F1': metrics['f1'],\n",
    "        }\n",
    "        results = pd.concat([results, pd.DataFrame([result])], ignore_index=True)\n",
    "        # 计算 95% CI\n",
    "        ci_data = {\n",
    "            'Dataset': dataset,\n",
    "            'Model': name,\n",
    "            'ACC': res_ci['accuracy'],\n",
    "            'AUC': res_ci['auc'],\n",
    "            'Sensitivity': res_ci['sensitivity'],\n",
    "            'Specificity': res_ci['specificity'],\n",
    "            'NPV': res_ci['npv'],\n",
    "            'PPV': res_ci['ppv'],\n",
    "            'F1': res_ci['f1'],\n",
    "        }\n",
    "        ci_results = pd.concat([ci_results, pd.DataFrame([ci_data])], ignore_index=True)\n",
    "# 显示结果\n",
    "display(results)\n",
    "# 保存模型性能指标和95%置信区间到CSV文件\n",
    "results.to_csv('results/model_performance_metrics.csv', index=False)\n",
    "ci_results.to_csv('results/model_performance_metrics_CI.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ci_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.inspection import permutation_importance\n",
    "for name, model in models:\n",
    "        print(f\"Plotting feature importance for {name}...\")\n",
    "        feature_importance = None\n",
    "        if hasattr(model, 'feature_importances_'):\n",
    "            feature_importance = model.feature_importances_\n",
    "        elif hasattr(model, 'coef_'):\n",
    "            feature_importance = np.abs(model.coef_[0])\n",
    "        else:\n",
    "            result = permutation_importance(model, x_train, y_train, n_repeats=30, random_state=42, n_jobs=-1)\n",
    "            feature_importance = result.importances_mean.argsort()\n",
    "        \n",
    "        feature_importance_df = pd.DataFrame({\n",
    "            'Feature': x_train.columns,\n",
    "            'Importance': feature_importance\n",
    "        })\n",
    "        feature_importance_df = feature_importance_df.sort_values(by='Importance', ascending=False)\n",
    "        \n",
    "        plt.figure(figsize=(10, 6))\n",
    "        plt.barh(feature_importance_df['Feature'], feature_importance_df['Importance'])\n",
    "        plt.xlabel(\"Feature Importance\")\n",
    "        plt.ylabel(\"Feature\")\n",
    "        plt.title(f\"{name} Feature Importance\")\n",
    "        plt.gca().invert_yaxis()\n",
    "        plt.grid(False)\n",
    "        plt.savefig(f\"results/img/{name}_feature_importance.svg\", bbox_inches='tight')\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import auc\n",
    "from pixelmed_calc.medical_imaging.Ploting.plot_metric import plot_multiple_ROCs\n",
    "  \n",
    "for name in proba_dict_test:\n",
    "    y_truths_list=[y_train,y_test]\n",
    "    y_scores_list=[proba_dict_train[name],proba_dict_test[name]]\n",
    "    plot_multiple_ROCs(y_truths_list,y_scores_list,models=['train','val','test'],title=name)\n",
    "    plt.savefig(f'results/img/{name}_roc.svg')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from pixelmed_calc.medical_imaging.Ploting.plot_metric import plot_calibration_curves\n",
    "from pixelmed_calc.medical_imaging.RadiologyComponents.components1 import HosmerLemeshow\n",
    "for name in proba_dict_test:\n",
    "    y_truths_list=[y_train,y_test]\n",
    "    y_scores_list=[proba_dict_train[name],proba_dict_test[name]]\n",
    "    plot_calibration_curves(y_truths_list,y_scores_list,models=['train','val','test'],title=name)\n",
    "    hl_result_train = HosmerLemeshow(proba_dict_train[name], y_train,Q=5)\n",
    "    print(f'{name} train:\\n{hl_result_train}')\n",
    "    hl_result_test = HosmerLemeshow(proba_dict_test[name], y_test,Q=5)\n",
    "    print(f'{name} val:\\n {hl_result_test}')\n",
    "    plt.savefig(f'results/img/{name}_calibrated.svg')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from pixelmed_calc.medical_imaging.Ploting.plot_metric import plot_DCA_curve\n",
    "\n",
    "# Example usage:\n",
    "for names in models:\n",
    "    intersection_points_x_axis, intersection_points_model_vs_all = plot_DCA_curve(proba_dict_test[names[0]], y_test,model=names[0])\n",
    "    print(\"Intersection points with x-axis:\", intersection_points_x_axis)\n",
    "    print(\"Intersection points between net_benefit_model and net_benefit_all:\", intersection_points_model_vs_all)\n",
    "    plt.savefig(f\"results/img/{names[0]}_dca.svg\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "delong 检验"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import combinations\n",
    "import pandas as pd\n",
    "from pixelmed_calc.medical_imaging.RadiologyComponents.delong import delong_roc_test\n",
    "\n",
    "# List of models and data types\n",
    "model_names =[]\n",
    "for name, model in models:\n",
    "    model_names.append(name)\n",
    "data_types = ['test', 'train']\n",
    "\n",
    "# Prepare to collect results\n",
    "results = []\n",
    "\n",
    "# Note: Assuming y_test_sel and y_train_sel are defined elsewhere in your code\n",
    "# ground_truth for test and train data\n",
    "ground_truth_test = y_test\n",
    "ground_truth_train = y_train\n",
    "\n",
    "# Generate all combinations of model comparisons for each data type\n",
    "for sm1, sm2 in combinations(model_names, 2):\n",
    "    for data_type in data_types:\n",
    "        predictions_one = pd.read_csv(f'results/pred/{sm1}_{data_type}_proba.csv')\n",
    "        predictions_two = pd.read_csv(f'results/pred/{sm2}_{data_type}_proba.csv')\n",
    "        \n",
    "        # Select appropriate ground_truth based on data_type\n",
    "        ground_truth = ground_truth_train if data_type == 'train' else ground_truth_test\n",
    "        \n",
    "        delong = delong_roc_test(ground_truth, predictions_one['proba'], predictions_two['proba'])\n",
    "        \n",
    "        # Collect each comparison's results\n",
    "        results.append({\n",
    "            'Model 1': sm1,\n",
    "            'Model 2': sm2,\n",
    "            'Data Type': data_type,\n",
    "            'P-Value': delong[0][0],\n",
    "            'Z-Value': delong[1][0]\n",
    "        })\n",
    "\n",
    "# Convert results into a DataFrame\n",
    "results_df = pd.DataFrame(results)\n",
    "\n",
    "# Display the DataFrame\n",
    "results_df.to_csv('results/delong_test.csv')\n",
    "results_df\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pm38web",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
