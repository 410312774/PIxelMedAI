{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 导入数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "os.makedirs('results/img', exist_ok=True)\n",
    "os.makedirs('results/model_weight', exist_ok=True)\n",
    "os.makedirs('results/pred', exist_ok=True)\n",
    "inputfile = 'DL_radmico_imagenet.csv'\n",
    "labelfile= 'label_class2.csv'\n",
    "data_feature=pd.read_csv(inputfile)\n",
    "mean_values = data_feature.loc[:, data_feature.columns != 'ID'].mean()\n",
    "data_feature.fillna(mean_values, inplace=True)\n",
    "data_label=pd.read_csv(labelfile)\n",
    "merged_data = pd.merge(data_feature, data_label, on='ID')\n",
    "merged_data.columns = merged_data.columns.str.replace(r'-', '_')\n",
    "merged_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "plt.rcParams['figure.dpi'] = 300\n",
    "category_counts = merged_data.columns[1:-2].map(lambda x: x.split('_')[-2]).value_counts()\n",
    "category_counts_percent = category_counts / category_counts.sum() * 100\n",
    "display('特征个数统计：',category_counts)\n",
    "# 设置Seaborn的风格\n",
    "sns.set(style=\"whitegrid\")\n",
    "# 创建一个颜色调色板\n",
    "colors = sns.color_palette('pastel')[0:len(category_counts_percent)]\n",
    "# 创建3D效果的饼图\n",
    "fig, ax = plt.subplots(figsize=(12, 12), subplot_kw=dict(aspect=\"equal\"))\n",
    "wedges, texts, autotexts = ax.pie(category_counts_percent, labels=category_counts_percent.index, autopct='%1.1f%%', startangle=140,\n",
    "                                  colors=colors, wedgeprops=dict(width=0.3, edgecolor='w'))\n",
    "# 添加阴影效果以增强立体感\n",
    "for wedge in wedges:\n",
    "    wedge.set_edgecolor('w')\n",
    "    wedge.set_linewidth(8)\n",
    "# 添加中心白色圆圈使其成为环形图\n",
    "centre_circle = plt.Circle((0, 0), 0.2, fc='white', edgecolor='w')\n",
    "fig.gca().add_artist(centre_circle)\n",
    "# 调整文字和自动文字的样式\n",
    "plt.setp(texts, size=15, weight=\"bold\")\n",
    "plt.setp(autotexts, size=10, weight=\"bold\", color=\"white\")\n",
    "# 设置标题\n",
    "#ax.set_title('特征大类所占比例', fontsize=16)\n",
    "# 显示图表\n",
    "plt.tight_layout()\n",
    "plt.savefig('results/img/特征大类所占比例.svg')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "数据集包含较多的异常值，使用稳键归一化（robust normalization）\n",
    "value_result = (value-Media)/(Q1-Q3)  \n",
    "Q1的位置 = 1 * （n + 1) / 4  \n",
    "Q3的位置 =  3 *（n + 1) / 4  \n",
    "n : 表示数据的个数。  \n",
    "media : 中位数  \n",
    "Q1 : 是第 1 个四分位数（第 25 个分位数）  \n",
    "Q3 : 第 3 个四分位数（第 75 个分位数） \n",
    "\n",
    "method='robust' 稳键归一化,standard（z值标准化）,minmax（最大最小值标准化）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pixelmed_calc.medical_imaging.RadiologyComponents.components1 import sel_standard_data\n",
    "#method='robust',standard,minmax\n",
    "merged_data = sel_standard_data(merged_data, merged_data.columns[1:-2],method='robust')\n",
    "merged_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## F检验筛选特征\n",
    "\n",
    "多组比较：F检验通常用于分析方差分析（ANOVA），它可以同时比较三个或更多的组别。而T检验通常用于两组数据的比较。 \n",
    " 方差齐性检验：在进行T检验之前，通常需要先检验数据的方差是否齐性。F检验可以直接用于检验方差是否相等，这是T检验无法做到的。  \n",
    " 控制类型I错误：在进行多重比较的情况下，T检验可能会增加犯类型I错误的风险。而F检验通过调整P值，可以更好地控制这一风险。  \n",
    " 更广泛的适用性：F检验不仅限于两样本均值的比较，它还适用于多个样本均值的比较，以及因子水平的比较。  \n",
    " 实验设计：F检验可以应用于完全随机设计、随机区组设计、拉丁方设计等多种实验设计，而T检验通常只适用于两组独立样本或配对样本。  \n",
    " 多重比较问题：当涉及到多个比较时，F检验可以通过调整方法（如Bonferroni校正）来控制整体错误率，而T检验在多重比较时可能需要更复杂的方法来控制错误率。  \n",
    " 统计功效：在某些情况下，F检验可能具有比T检验更高的统计功效，尤其是在样本量较大时。  \n",
    " 非正态分布数据：虽然T检验和F检验都假设数据正态分布，但在实际应用中，F检验对于数据分布的正态性要求可能稍微宽松一些。  \n",
    "\n",
    "\n",
    " method='f_test',t_test,chi2_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pixelmed_calc.medical_imaging.RadiologyComponents.components1 import select_significant_features\n",
    "\n",
    "significant_features_sel, feature_scores=select_significant_features(merged_data, label_column='label', columns=merged_data.columns[1:-2],significance_level=0.05,method='f_test')\n",
    "feature_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set(style=\"whitegrid\")\n",
    "# 使用Seaborn绘制小提琴图\n",
    "plt.figure(figsize=(15, 10))\n",
    "# 使用不同的调色板，并将x变量分配给hue，关闭图例显示\n",
    "sns.violinplot(x='Category', y='p_value', data=feature_scores, hue='Category', palette=\"coolwarm\", legend=False)\n",
    "# 添加水平网格线以提高图形的可读性\n",
    "plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "# 设置标题和坐标标签的字体大小和风格\n",
    "plt.title('P value distribution', fontsize=20, weight='bold')\n",
    "plt.xlabel('Feature Category', fontsize=18)\n",
    "plt.ylabel('p value', fontsize=18)\n",
    "# 调整x轴标签的字体大小并旋转\n",
    "plt.xticks(fontsize=14, rotation=45, weight='bold')\n",
    "# 调整y轴标签的字体大小\n",
    "plt.yticks(fontsize=14, weight='bold')\n",
    "# 移动图例的位置并调整字体大小（由于关闭了图例显示部分，不再需要）\n",
    "# plt.legend(title='特征大类', title_fontsize='13', loc='upper right', fontsize='11')\n",
    "# 添加紧凑布局以防止图形元素重叠\n",
    "plt.tight_layout()\n",
    "# 显示图表\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set(style=\"whitegrid\")\n",
    "# 使用 Seaborn 绘制箱线图\n",
    "plt.figure(figsize=(15, 10))\n",
    "# 使用不同的调色板，并将 x 变量分配给 hue，关闭图例显示\n",
    "sns.boxplot(hue='Category', y='p_value', data=feature_scores, palette=\"coolwarm\")\n",
    "# 添加水平网格线以提高图形的可读性\n",
    "plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "# 设置标题和坐标标签的字体大小和风格\n",
    "plt.title('P value distribution', fontsize=20, weight='bold')\n",
    "plt.xlabel('Feature Category', fontsize=18)\n",
    "plt.ylabel('p value', fontsize=18)\n",
    "\n",
    "# 调整 x 轴标签的字体大小并旋转\n",
    "plt.xticks(fontsize=14, rotation=45, weight='bold')\n",
    "# 调整 y 轴标签的字体大小\n",
    "plt.yticks(fontsize=14, weight='bold')\n",
    "# 添加紧凑布局以防止图形元素重叠\n",
    "plt.tight_layout()\n",
    "# 显示图表\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np  \n",
    "import pandas as pd  \n",
    "from pixelmed_calc.medical_imaging.RadiologyComponents.components1 import filter_highly_correlated_features\n",
    "\n",
    "final_significant_features, removed_features = filter_highly_correlated_features(merged_data, significant_features_sel,'pearson',correlation_threshold=0.9)  \n",
    "\n",
    "print(f\"最终筛选的特征数量: {len(final_significant_features)}\")  \n",
    "print(final_significant_features)  \n",
    "\n",
    "print(f\"移除的特征: {removed_features}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_sel=merged_data[list(final_significant_features)+['label','group']]\n",
    "data_sel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train=data_sel[data_sel['group']=='train'].drop(['group','label'],axis=1)\n",
    "y_train=data_sel[data_sel['group']=='train']['label']\n",
    "\n",
    "x_test=data_sel[data_sel['group']=='test'].drop(['group','label'],axis=1)\n",
    "y_test=data_sel[data_sel['group']=='test']['label']\n",
    "\n",
    "x_all=data_sel.drop(['group','label'],axis=1)\n",
    "y_all=data_sel['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.linear_model import Lasso\n",
    "from pixelmed_calc.medical_imaging.RadiologyComponents.components1 import find_best_alpha\n",
    "alphas = np.logspace(-6,2,50)\n",
    "best_alpha,scores_lasso,scores_std_lasso=find_best_alpha(x_train, y_train,alphas=alphas)\n",
    "\n",
    "lasso = Lasso(alpha=best_alpha)\n",
    "lasso.fit(x_train, y_train)\n",
    "# 输出系数\n",
    "lasso_coefs = lasso.coef_\n",
    "# 创建 DataFrame 显示特征名和对应的系数\n",
    "coef_df = pd.DataFrame({'feature': x_train.columns, 'coef': lasso_coefs})\n",
    "selected_features = coef_df[abs(coef_df['coef']) > 1e-2]\n",
    "# 创建 DataFrame 显示特征名和对应的系数\n",
    "print(f\"选择的特征:\\n{selected_features}\")\n",
    "lasso_sel_cloumn=selected_features['feature']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import numpy as np\n",
    "plt.rcParams['figure.dpi'] = 300\n",
    "# 设置不同的alpha值范围\n",
    "alpha_values = [0.0001,0.001,0.002,0.005,0.008,0.01,0.1,1,10,50,100]#alphas\n",
    "lasso = Lasso(max_iter=1000)\n",
    "coefs = []\n",
    "num_nonzero_coefs = []\n",
    "for a in alpha_values:\n",
    "    lasso.set_params(alpha=a)\n",
    "    lasso.fit(x_train, y_train)\n",
    "    coefs.append(lasso.coef_)\n",
    "    num_nonzero_coefs.append(np.sum(lasso.coef_ != 0))\n",
    "ax = plt.gca()\n",
    "ax.plot(alpha_values, coefs)\n",
    "ax.set_xscale('log')\n",
    "plt.axis('tight')\n",
    "plt.xlabel(f'Log({best_alpha:.3f})')\n",
    "plt.ylabel('Coefficients')\n",
    "plt.title('Lasso coefficients as a function of alpha')\n",
    "plt.axvline(x=best_alpha, linestyle='--', color='r')\n",
    "plt.grid(False)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "平均分数计算：在完成所有交叉验证迭代后，GridSearchCV会计算每个参数组合在所有测试集上的平均得分。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "plt.figure().set_size_inches(8, 6)\n",
    "plt.semilogx(alphas, scores_lasso)\n",
    "# 显示误差线，显示+/-标准。 分数错误\n",
    "std_error = scores_std_lasso / np.sqrt(10)\n",
    "plt.semilogx(alphas, scores_lasso + std_error, 'b--')\n",
    "plt.semilogx(alphas, scores_lasso - std_error, 'b--')\n",
    "# alpha = 0.2控制填充颜色的半透明性\n",
    "plt.fill_between(alphas, scores_lasso + std_error, scores_lasso - std_error, alpha=0.2)\n",
    "plt.axvline(x=best_alpha, linestyle='--', color='r')\n",
    "plt.ylabel('CV score +/- std error')\n",
    "plt.xlabel(f'alpha({best_alpha:.3f})')\n",
    "plt.axhline(np.max(scores_lasso), linestyle='--', color='.5')\n",
    "plt.xlim([alphas[0], alphas[-1]])\n",
    "plt.grid(False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train=x_train[lasso_sel_cloumn]\n",
    "x_test=x_test[lasso_sel_cloumn]\n",
    "x_all=x_all[lasso_sel_cloumn]\n",
    "x_train.to_csv('results/pred/x_train.csv',index=False) \n",
    "x_test.to_csv('results/pred/x_test.csv',index=False)\n",
    "y_train.to_csv('results/pred/y_train.csv',index=False)\n",
    "y_test.to_csv('results/pred/y_test.csv',index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier,ExtraTreesClassifier,AdaBoostClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from xgboost.sklearn import XGBClassifier\n",
    "from lightgbm.sklearn import LGBMClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "models = [('LR', LogisticRegression(random_state=0)),\n",
    "          ('NB',GaussianNB()),\n",
    "          ('linear_SVM', SVC(kernel='linear',class_weight='balanced',probability=True,max_iter=1000)),\n",
    "          ('poly_SVM',SVC(kernel='poly',class_weight='balanced',probability=True)),\n",
    "          ('sigmoid_SVM',SVC(kernel='sigmoid',class_weight='balanced',probability=True)),\n",
    "          ('rbf_SVM',SVC(kernel='rbf',class_weight='balanced',probability=True)),\n",
    "          ('DT', DecisionTreeClassifier(class_weight='balanced')),\n",
    "          ('RF', RandomForestClassifier(class_weight='balanced')),\n",
    "          ('ExtraTree', ExtraTreesClassifier(class_weight='balanced')),\n",
    "          ('XGBoost', XGBClassifier(class_weight='balanced')),\n",
    "          ('AdaBoost',AdaBoostClassifier(n_estimators=10, random_state=0)),\n",
    "          ('MLP',MLPClassifier(hidden_layer_sizes=(128, 64, 32), max_iter=200, solver='adam', random_state=42)),\n",
    "          ('GBM',GradientBoostingClassifier(n_estimators=10, random_state=0)),\n",
    "          ('LightGBM',LGBMClassifier(n_estimators=10, max_depth=-1, objective='multiclass',verbosity=-1))]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np  \n",
    "import pandas as pd  \n",
    "import warnings  \n",
    "import logging  \n",
    "import joblib  \n",
    "from pixelmed_calc.medical_imaging.RadiologyComponents.components1 import calculate_metrics_with_ci  \n",
    "\n",
    "warnings.filterwarnings('ignore')  \n",
    "logging.getLogger('LightGBM').setLevel(logging.ERROR)  # Only log errors  \n",
    "\n",
    "# Create DataFrames to store results  \n",
    "results = pd.DataFrame(columns=['Dataset', 'Model', 'Class', 'Threshold', 'ACC', 'AUC', 'Sensitivity', 'Specificity', 'NPV', 'PPV', 'F1'])  \n",
    "ci_results = pd.DataFrame(columns=['Dataset', 'Model', 'Class', 'ACC', 'AUC', 'Sensitivity', 'Specificity', 'NPV', 'PPV', 'F1'])  \n",
    "proba_dict_train = {}\n",
    "proba_dict_test = {}\n",
    "\n",
    "train_ids = merged_data[merged_data['group'] == 'train']['ID'].values\n",
    "test_ids = merged_data[merged_data['group'] == 'test']['ID'].values\n",
    "# Train and test all models  \n",
    "for name, model in models:  \n",
    "    print(f\"Training {name}...\")  \n",
    "    model.fit(x_train, y_train)  \n",
    "    joblib.dump(model, f\"results/model_weight/{name}.pkl\")  \n",
    "    \n",
    "    # Get predictions  \n",
    "    y_train_proba = model.predict_proba(x_train)  \n",
    "    y_test_proba = model.predict_proba(x_test)  \n",
    "    y_train_pred = np.argmax(y_train_proba, axis=1)  \n",
    "    y_test_pred = np.argmax(y_test_proba, axis=1)  \n",
    "\n",
    "    proba_dict_train[name] = y_train_proba\n",
    "    proba_dict_test[name] = y_test_proba\n",
    "\n",
    "    train_output = pd.DataFrame(y_train_proba, columns=[f'class_{i}_proba' for i in range(y_train_proba.shape[1])])  \n",
    "    train_output.insert(0, 'ID', train_ids)  \n",
    "    train_output.to_csv(f'results/pred/{name}_train_proba.csv', index=False)  \n",
    "\n",
    "    test_output = pd.DataFrame(y_test_proba, columns=[f'class_{i}_proba' for i in range(y_test_proba.shape[1])])  \n",
    "    test_output.insert(0, 'ID', test_ids)  \n",
    "    test_output.to_csv(f'results/pred/{name}_test_proba.csv', index=False)  \n",
    "    # Loop over each class to calculate metrics  \n",
    "    for phase, (x, y, y_pred, y_proba) in zip(['Train', 'Test'],   \n",
    "                                               [(x_train, y_train, y_train_pred, y_train_proba),   \n",
    "                                                (x_test, y_test, y_test_pred, y_test_proba)]):  \n",
    "        for class_idx in range(y_proba.shape[1]):  \n",
    "            y_true_bin = (y == class_idx).astype(int)  \n",
    "            y_pred_bin = (y_pred == class_idx).astype(int)  \n",
    "            y_proba_bin = y_proba[:, class_idx]  \n",
    "            \n",
    "            # Calculate metrics and confidence intervals  \n",
    "            metrics, ci = calculate_metrics_with_ci(np.array(y_true_bin), np.array(y_proba_bin), n_bootstrap=100)  \n",
    "            \n",
    "            # Create result dictionaries  \n",
    "            result = {  \n",
    "                'Dataset': phase,  \n",
    "                'Model': name,  \n",
    "                'Class': class_idx,  \n",
    "                'Threshold': metrics['threshold'],  \n",
    "                'ACC': metrics['accuracy'],  \n",
    "                'AUC': metrics['auc'],  \n",
    "                'Sensitivity': metrics['sensitivity'],  \n",
    "                'Specificity': metrics['specificity'],  \n",
    "                'NPV': metrics['npv'],  \n",
    "                'PPV': metrics['ppv'],  \n",
    "                'F1': metrics['f1'],  \n",
    "            }  \n",
    "            \n",
    "            ci_data = {  \n",
    "                'Dataset': phase,  \n",
    "                'Model': name,  \n",
    "                'Class': class_idx,  \n",
    "                'ACC': ci['accuracy'],  \n",
    "                'AUC': ci['auc'],  \n",
    "                'Sensitivity': ci['sensitivity'],  \n",
    "                'Specificity': ci['specificity'],  \n",
    "                'NPV': ci['npv'],  \n",
    "                'PPV': ci['ppv'],  \n",
    "                'F1': ci['f1'],  \n",
    "            }  \n",
    "            # Append results to DataFrames  \n",
    "            results = pd.concat([results, pd.DataFrame([result])], ignore_index=True)  \n",
    "            ci_results = pd.concat([ci_results, pd.DataFrame([ci_data])], ignore_index=True)  \n",
    "\n",
    "# Output results  \n",
    "display(results)  \n",
    "display(ci_results)  \n",
    "results.to_csv('results/results.csv', index=False)  \n",
    "ci_results.to_csv('results/ci_results.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.inspection import permutation_importance\n",
    "for name, model in models:\n",
    "        print(f\"Plotting feature importance for {name}...\")\n",
    "        feature_importance = None\n",
    "        if hasattr(model, 'feature_importances_'):\n",
    "            feature_importance = model.feature_importances_\n",
    "        elif hasattr(model, 'coef_'):\n",
    "            feature_importance = np.abs(model.coef_[0])\n",
    "        else:\n",
    "            result = permutation_importance(model, x_train, y_train, n_repeats=30, random_state=42, n_jobs=-1)\n",
    "            feature_importance = result.importances_mean.argsort()\n",
    "        \n",
    "        feature_importance_df = pd.DataFrame({\n",
    "            'Feature': x_train.columns,\n",
    "            'Importance': feature_importance\n",
    "        })\n",
    "        feature_importance_df = feature_importance_df.sort_values(by='Importance', ascending=False)\n",
    "        \n",
    "        plt.figure(figsize=(10, 6))\n",
    "        plt.barh(feature_importance_df['Feature'], feature_importance_df['Importance'])\n",
    "        plt.xlabel(\"Feature Importance\")\n",
    "        plt.ylabel(\"Feature\")\n",
    "        plt.title(f\"{name} Feature Importance\")\n",
    "        plt.gca().invert_yaxis()\n",
    "        plt.grid(False)\n",
    "        plt.savefig(f\"results/img/{name}_feature_importance.svg\", bbox_inches='tight')\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from pixelmed_calc.medical_imaging.Ploting.plot_metric import plot_multiclass_roc\n",
    "  \n",
    "for name in proba_dict_train:\n",
    "    plot_multiclass_roc(y_train,proba_dict_train[name],model_name=name)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from pixelmed_calc.medical_imaging.Ploting.plot_metric import plot_multiclass_roc\n",
    "  \n",
    "for name in proba_dict_test:\n",
    "    plot_multiclass_roc(y_test,proba_dict_test[name],model_name=name)\n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pm38web",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
