{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-11T00:11:36.547861Z",
     "start_time": "2023-07-11T00:11:36.080601Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from IPython.display import display\n",
    "os.environ['KMP_DUPLICATE_LIB_OK'] = 'TRUE'\n",
    "from pixelmed_calc import get_param_in_cwd\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams['figure.dpi'] = 300\n",
    "\n",
    "os.makedirs('img', exist_ok=True)\n",
    "os.makedirs('results', exist_ok=True)\n",
    "#特征文件\n",
    "featurePath='DL_radmico_imagenet.csv'\n",
    "# 对应的标签文件\n",
    "group_info = get_param_in_cwd('dataset_column')\n",
    "labelf = get_param_in_cwd('label_file')\n",
    "# 读取标签数据列名\n",
    "labels = [get_param_in_cwd('task_column') or 'label']\n",
    "#读取特征文件\n",
    "if os.path.exists(featurePath):\n",
    "    rad_data = pd.read_csv(featurePath, header=0)\n",
    "    rad_data.columns = [c.replace('-', '_') for c in rad_data.columns]\n",
    "rad_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 特征统计"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-10T23:25:37.934975Z",
     "start_time": "2023-07-10T23:25:37.465753Z"
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "sorted_counts = pd.DataFrame([c.split('_')[-2] for c in rad_data.columns if c !='ID']).value_counts()\n",
    "sorted_counts = pd.DataFrame(sorted_counts, columns=['count']).reset_index()\n",
    "sorted_counts = sorted_counts.sort_values(0)\n",
    "display(sorted_counts)\n",
    "plt.pie(sorted_counts['count'], labels=[i for i in sorted_counts[0]], startangle=0,\n",
    "        counterclock = False, autopct = '%.1f%%')\n",
    "plt.savefig(f'img/Rad_feature_ratio.svg', bbox_inches = 'tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 标注数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-10T23:25:44.564313Z",
     "start_time": "2023-07-10T23:25:44.553603Z"
    }
   },
   "outputs": [],
   "source": [
    "label_data = pd.read_csv(labelf)\n",
    "label_data['ID'] = label_data['ID'].map(lambda x: f\"{x}.nii.gz\" if not (f\"{x}\".endswith('.nii.gz') or  f\"{x}\".endswith('.nii')) else x)\n",
    "label_data = label_data[['ID', 'group'] + labels]\n",
    "label_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 特征拼接"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-10T23:25:47.788917Z",
     "start_time": "2023-07-10T23:25:47.142658Z"
    }
   },
   "outputs": [],
   "source": [
    "combined_data = pd.merge(rad_data, label_data, on=['ID'], how='inner')\n",
    "ids = combined_data['ID']\n",
    "combined_data = combined_data.drop(['ID'], axis=1)\n",
    "print(combined_data[labels].value_counts())\n",
    "combined_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 获取数据统计信息"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-10T23:25:53.199785Z",
     "start_time": "2023-07-10T23:25:50.941862Z"
    }
   },
   "outputs": [],
   "source": [
    "combined_data.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# z值标准化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-10T23:26:11.606571Z",
     "start_time": "2023-07-10T23:25:56.373716Z"
    }
   },
   "outputs": [],
   "source": [
    "from pixelmed_calc.custom.components.comp1 import normalize_df\n",
    "data = normalize_df(combined_data, not_norm=labels, group=group_info)\n",
    "data = data.dropna(axis=1)\n",
    "data.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 统计检验，不是标配"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-10T23:29:04.677726Z",
     "start_time": "2023-07-10T23:28:49.485261Z"
    }
   },
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "from pixelmed_calc.custom.components.stats import clinic_stats\n",
    "\n",
    "stats = clinic_stats(data[data['group'] == 'train'], stats_columns=list(data.columns[0:-2]), label_column=labels[0],\n",
    "                     continuous_columns=list(data.columns[0:-2]))\n",
    "stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-10T23:29:29.953418Z",
     "start_time": "2023-07-10T23:29:28.802740Z"
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def map2float(x):\n",
    "    try:\n",
    "        return float(str(x)[1:])\n",
    "    except:\n",
    "        return 1\n",
    "\n",
    "stats[['pvalue']] = stats[['pvalue']].applymap(map2float)\n",
    "stats[['group']] = stats[['feature_name']].applymap(lambda x: x.split('_')[-2])\n",
    "stats = stats[['feature_name', 'pvalue', 'group']]\n",
    "g = sns.catplot(x=\"group\", y=\"pvalue\", data=stats, kind=\"violin\")\n",
    "g.fig.set_size_inches(15,10)\n",
    "sns.stripplot(x=\"group\", y=\"pvalue\", data=stats, ax=g.ax, color='black')\n",
    "plt.savefig(f'img/Rad_feature_stats.svg', bbox_inches = 'tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 通过p值筛选特征"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-10T23:29:33.859673Z",
     "start_time": "2023-07-10T23:29:33.834420Z"
    }
   },
   "outputs": [],
   "source": [
    "pvalue = 0.01\n",
    "sel_feature = list(stats[stats['pvalue'] < pvalue]['feature_name']) + labels + [group_info]\n",
    "data = data[sel_feature]\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 通过相关系数筛选特征"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-10T23:29:36.457822Z",
     "start_time": "2023-07-10T23:29:36.423455Z"
    }
   },
   "outputs": [],
   "source": [
    "pearson_corr = data[data['group'] == 'train'][[c for c in data.columns if c not in labels]].corr('pearson')\n",
    "# kendall_corr = data[[c for c in data.columns if c not in labels]].corr('kendall')\n",
    "# spearman_corr = data[[c for c in data.columns if c not in labels]].corr('spearman')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-10T23:29:39.917710Z",
     "start_time": "2023-07-10T23:29:39.871205Z"
    }
   },
   "outputs": [],
   "source": [
    "from pixelmed_calc.custom.components.comp1 import select_feature\n",
    "sel_feature = select_feature(pearson_corr, threshold=0.9, topn=10, verbose=False)\n",
    "sel_feature = sel_feature + labels + [group_info]\n",
    "sel_feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-10T23:29:43.296812Z",
     "start_time": "2023-07-10T23:29:43.271722Z"
    }
   },
   "outputs": [],
   "source": [
    "#过滤特征\n",
    "sel_data = data[sel_feature]\n",
    "\n",
    "sel_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 构建数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-11T00:01:09.318858Z",
     "start_time": "2023-07-11T00:01:09.282439Z"
    }
   },
   "outputs": [],
   "source": [
    "n_classes = 3\n",
    "train_data = sel_data[(sel_data[group_info] == 'train')]\n",
    "train_ids = ids[train_data.index]\n",
    "train_data = train_data.reset_index()\n",
    "train_data = train_data.drop('index', axis=1)\n",
    "y_data = train_data[labels]\n",
    "X_data = train_data.drop(labels + [group_info], axis=1)\n",
    "\n",
    "test_data = sel_data[sel_data[group_info] == 'test']\n",
    "test_ids = ids[test_data.index]\n",
    "test_data = test_data.reset_index()\n",
    "test_data = test_data.drop('index', axis=1)\n",
    "y_test_data = test_data[labels]\n",
    "X_test_data = test_data.drop(labels + [group_info], axis=1)\n",
    "\n",
    "\n",
    "val_data = sel_data[sel_data[group_info] == 'val']\n",
    "val_ids = ids[val_data.index]\n",
    "val_data = val_data.reset_index()\n",
    "val_data = val_data.drop('index', axis=1)\n",
    "y_val_data = val_data[labels]\n",
    "X_val_data = val_data.drop(labels + [group_info], axis=1)\n",
    "\n",
    "val1_data = sel_data[sel_data[group_info] == 'val1']\n",
    "val1_ids = ids[val1_data.index]\n",
    "val1_data = val1_data.reset_index()\n",
    "val1_data = val1_data.drop('index', axis=1)\n",
    "y_val1_data = val1_data[labels]\n",
    "X_val1_data = val1_data.drop(labels + [group_info], axis=1)\n",
    "\n",
    "y_all_data = sel_data[labels]\n",
    "X_all_data = sel_data.drop(labels + [group_info], axis=1)\n",
    "\n",
    "column_names = X_data.columns\n",
    "print(f\"训练集样本数：{X_data.shape}, 测试集样本数：{X_test_data.shape}，验证集样本数：{X_val_data.shape},验证集1样本数：{X_val1_data.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# lasso 回归"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-10T23:29:52.635139Z",
     "start_time": "2023-07-10T23:29:50.946656Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pixelmed_calc.custom.components as okcomp\n",
    "\n",
    "alpha = okcomp.comp1.lasso_cv_coefs(X_data, y_data, column_names=None)\n",
    "plt.savefig(f'img/Rad_feature_lasso.svg', bbox_inches = 'tight')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-10T23:29:59.484673Z",
     "start_time": "2023-07-10T23:29:58.269838Z"
    }
   },
   "outputs": [],
   "source": [
    "#模型效能\n",
    "okcomp.comp1.lasso_cv_efficiency(X_data, y_data, points=50)\n",
    "plt.savefig(f'img/Rad_feature_mse.svg', bbox_inches = 'tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-10T23:30:02.857158Z",
     "start_time": "2023-07-10T23:30:02.839661Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn import linear_model\n",
    "\n",
    "models = []\n",
    "for label in labels:\n",
    "    clf = linear_model.Lasso(alpha=alpha) #如果系数都等于0可以调小alpha ，比如alpha=0.01\n",
    "    clf.fit(X_data, y_data[label])\n",
    "    models.append(clf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 特征筛选\n",
    "\n",
    "筛选出其中coef > 0的特征。并且打印出相应的公式。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-10T23:30:11.030608Z",
     "start_time": "2023-07-10T23:30:11.012289Z"
    }
   },
   "outputs": [],
   "source": [
    "COEF_THRESHOLD = 1e-6 # 筛选的特征阈值\n",
    "scores = []\n",
    "selected_features = []\n",
    "for label, model in zip(labels, models):\n",
    "    feat_coef = [(feat_name, coef) for feat_name, coef in zip(column_names, model.coef_)\n",
    "                 if COEF_THRESHOLD is None or abs(coef) > COEF_THRESHOLD]\n",
    "    print(feat_coef)\n",
    "    selected_features.append([feat for feat, _ in feat_coef])\n",
    "    formula = ' '.join([f\"{coef:+.6f} * {feat_name}\" for feat_name, coef in feat_coef])\n",
    "    score = f\"{label} = {model.intercept_} {'+' if formula[0] != '-' else ''} {formula}\"\n",
    "    scores.append(score)\n",
    "\n",
    "print(scores[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-10T23:30:14.757655Z",
     "start_time": "2023-07-10T23:30:13.810901Z"
    }
   },
   "outputs": [],
   "source": [
    "#特征权重\n",
    "feat_coef = sorted(feat_coef, key=lambda x: x[1])\n",
    "feat_coef_df = pd.DataFrame(feat_coef, columns=['feature_name', 'Coefficients'])\n",
    "feat_coef_df.plot(x='feature_name', y='Coefficients', kind='barh')\n",
    "\n",
    "plt.savefig(f'img/Rad_feature_weights.svg', bbox_inches = 'tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-10T23:30:17.762069Z",
     "start_time": "2023-07-10T23:30:17.735667Z"
    }
   },
   "outputs": [],
   "source": [
    "#进一步筛选特征\n",
    "X_data = X_data[selected_features[0]]\n",
    "X_test_data = X_test_data[selected_features[0]]\n",
    "X_val_data=X_val_data[selected_features[0]]\n",
    "X_val1_data=X_val1_data[selected_features[0]]\n",
    "\n",
    "#X_data.columns\n",
    "print(X_test_data.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 模型筛选"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-10T23:30:20.942145Z",
     "start_time": "2023-07-10T23:30:20.913525Z"
    }
   },
   "outputs": [],
   "source": [
    "#model_names = ['SVM', 'KNN', 'RandomForest', 'ExtraTrees', 'XGBoost', 'LightGBM', 'MLP', 'LR']\n",
    "\n",
    "model_names={'LightGBM':{\"objective\":\"multiclass\",\"num_classes\":3,\"n_estimators\":10, \"max_depth\":-1},\n",
    "             'SVM':{\"probability\":True, \"random_state\":0},\n",
    "             \"KNN\":{\"algorithm\":'kd_tree'},\n",
    "             \"RandomForest\":{\"n_estimators\":10, \"max_depth\":None,\"min_samples_split\":2, \"random_state\":0},\n",
    "             \"ExtraTrees\":{\"n_estimators\":10, \"max_depth\":None,\"min_samples_split\":2, \"random_state\":0},\n",
    "             \"XGBoost\":{\"n_estimators\":10, \"objective\":'binary:logistic',\"use_label_encoder\":False, \"eval_metric\":'error'},\n",
    "             \"MLP\":{\"hidden_layer_sizes\":(128, 64, 32), \"max_iter\":300, \"solver\":'sgd', \"random_state\":0},\n",
    "           \n",
    "            }\n",
    "\n",
    "models = okcomp.comp1.create_clf_model(model_names)\n",
    "model_names = list(models.keys())\n",
    "print(type(model_names))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 交叉验证挑数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-10T23:51:24.796381Z",
     "start_time": "2023-07-10T23:51:17.984990Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score\n",
    "# 随机使用n_trails次数据划分，找到最好的一次划分方法，并且保存在results中。\n",
    "results = okcomp.comp1.get_bst_split(X_data, y_data, models, test_size=0.2, metric_fn=accuracy_score, n_trails=5, cv=True, random_state=0)\n",
    "_, (X_train_sel, X_test_sel, y_train_sel, y_test_sel) = results['results'][results['max_idx']]\n",
    "trails, _ = zip(*results['results'])\n",
    "cv_results = pd.DataFrame(trails, columns=model_names)\n",
    "print(cv_results)\n",
    "# 可视化每个模型在不同的数据划分中的效果。\n",
    "sns.boxplot(data=cv_results)\n",
    "plt.ylabel('Accuracy %')\n",
    "plt.xticks(rotation=30)\n",
    "plt.xlabel('Model Nmae')\n",
    "plt.savefig(f'img/model_csv.svg', bbox_inches = 'tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 使用最好的数据划分"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-10T23:56:01.115416Z",
     "start_time": "2023-07-10T23:55:56.415799Z"
    }
   },
   "outputs": [],
   "source": [
    "import joblib\n",
    "from pixelmed_calc.custom.components.comp1 import plot_feature_importance\n",
    "import shap\n",
    "model_names={'LightGBM':{\"objective\":\"multiclass\",\"num_classes\":3,\"n_estimators\":10, \"max_depth\":-1},\n",
    "             'SVM':{\"probability\":True, \"random_state\":0},\n",
    "             \"KNN\":{\"algorithm\":'kd_tree'},\n",
    "             \"RandomForest\":{\"n_estimators\":10, \"max_depth\":None,\"min_samples_split\":2, \"random_state\":0},\n",
    "             \"ExtraTrees\":{\"n_estimators\":10, \"max_depth\":None,\"min_samples_split\":2, \"random_state\":0},\n",
    "             \"XGBoost\":{\"n_estimators\":10, \"objective\":'binary:logistic',\"use_label_encoder\":False, \"eval_metric\":'error'},\n",
    "             \"MLP\":{\"hidden_layer_sizes\":(128, 64, 32), \"max_iter\":300, \"solver\":'sgd', \"random_state\":0},\n",
    "             \"LR\":{\"random_state\":0}\n",
    "            }\n",
    "targets = []\n",
    "os.makedirs('models', exist_ok=True)\n",
    "for l in labels:\n",
    "    new_models = list(okcomp.comp1.create_clf_model(model_names).values())\n",
    "    for mn, m in zip(model_names, new_models):\n",
    "        print(m)\n",
    "        m=m.fit(X_train_sel, y_train_sel[l])\n",
    "        # 保存训练的模型\n",
    "        joblib.dump(m, f'models/Rad_{mn}_{l}.pkl')\n",
    "        # 输出模型特征重要性，只针对高级树模型有用\n",
    "        plot_feature_importance(m, selected_features[0], save_dir='img')\n",
    "  \n",
    "    targets.append(new_models)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 预测结果\n",
    "\n",
    "* predictions，二维数据，每个label对应的每个模型的预测结果。\n",
    "* pred_scores，二维数据，每个label对应的每个模型的预测概率值。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-10T23:58:54.701391Z",
     "start_time": "2023-07-10T23:58:54.477940Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from pixelmed_calc.custom.components.delong import calc_95_CI\n",
    "from pixelmed_calc.custom.components.metrics import analysis_pred_binary\n",
    "\n",
    "predictions = [[(model.predict(X_train_sel), model.predict(X_test_sel),model.predict(X_val_data),model.predict(X_val1_data))\n",
    "                for model in target] for label, target in zip(labels, targets)]\n",
    "pred_scores = [[(model.predict_proba(X_train_sel), model.predict_proba(X_test_sel),model.predict_proba(X_val_data),model.predict_proba(X_val1_data))\n",
    "                for model in target] for label, target in zip(labels, targets)]\n",
    "\n",
    "metric = []\n",
    "pred_sel_idx = []\n",
    "for label, prediction, scores in zip(labels, predictions, pred_scores):\n",
    "    pred_sel_idx_label = []\n",
    "    for mname, (train_pred, test_pred,val_pred,val1_pred), (train_score, test_score,val_score,val1_score) in zip(model_names, prediction, scores):\n",
    "        # 计算训练集指数\n",
    "        metric.append((mname, accuracy_score(y_train_sel[label], train_pred), f\"{label}-train\"))\n",
    "\n",
    "        # 计算验证集指标\n",
    "        metric.append((mname, accuracy_score(y_test_sel[label], test_pred), f\"{label}-test\"))\n",
    "\n",
    "        metric.append((mname, accuracy_score(y_val_data[label], val_pred), f\"{label}-val\"))\n",
    "\n",
    "        metric.append((mname, accuracy_score(y_val1_data[label], val1_pred), f\"{label}-val1\"))\n",
    "\n",
    "    pred_sel_idx.append(pred_sel_idx_label)\n",
    "metric = pd.DataFrame(metric, index=None, columns=['model_name', 'Accuracy', 'Task'])\n",
    "metric"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## shap vlaue 特征重要性\n",
    "### 二分类任务时\n",
    "当使用 LightGBM 模型时,shap values 会分为两类:\n",
    "\n",
    "每棵树的 SHAP values\n",
    "所有树的总体 SHAP values\n",
    "而 XGBoost 只会返回总体的 SHAP values。\n",
    "\n",
    "LightGBM 在计算 SHAP values 时,会先计算每棵树的 SHAP values,然后再把所有树的 SHAP values 汇总起来得到一个总体的 SHAP values。\n",
    "对 LightGBM 模型时,返回的 shap_values 包含:\n",
    "\n",
    "shap_values[0]: 每棵树的 SHAP values\n",
    "shap_values[1]: 总体的 SHAP values\n",
    "而对 XGBoost 模型时,只返回总体的 SHAP values,所以 shap_values 只有一个元素。\n",
    "\n",
    "这是 LightGBM 和 XGBoost 在计算 SHAP 的实现上的不同所导致的。总体来说,我们更关心的是最后的总体 SHAP values,所以可以只使用 shap_values[1]。\n",
    "\n",
    "### 当使用多分类任务时：\n",
    "当进行多分类任务时,LightGBM 模型计算出的 SHAP values 矩阵形状中的最后一个数字表示的是类别的个数。\n",
    "\n",
    "也就是说,对于3分类的任务,shap_values 的形状是 (样本数,特征数,3)。\n",
    "\n",
    "这里的3表示有3个类别,并不是树的个数。树的个数是计算SHAP values时的中间结果,最终输出到shap_values中的是按类别划分好的SHAP values。\n",
    "\n",
    "所以如果是二分类,shap_values 形状会是(样本数,特征数,2)。如果是单分类回归,那就只有(样本数,特征数)两个维度。\n",
    "\n",
    "综上,最后一个数字表示类别个数,而不是树的个数。对于多分类问题,我们需要为每个类别计算单独的一组 SHAP values,才能 fully explain 模型的预测。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "shap_model=models['XGBoost'].fit(X_train_sel, y_train_sel[l])\n",
    "\n",
    "import shap\n",
    "explainer = shap.TreeExplainer(shap_model)\n",
    "shap_values = explainer.shap_values(X_train_sel) \n",
    "shap_values2=explainer(X_train_sel)[:, :, 0] # [:, :, 0]只保留对第一个类别的shap值,否则LightGBM模型会多输出会报错，XGBoost则不会\n",
    "print('shap_values:',np.array(shap_values).shape)\n",
    "print('shap_values2:',explainer(X_train_sel)[:, :, 0].shape)\n",
    "\n",
    "#print(shap_values2)\n",
    "shap.summary_plot(shap_values, X_train_sel,plot_type=\"bar\",max_display=8)\n",
    "shap.plots.beeswarm(shap_values2,max_display=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "expected_value = explainer.expected_value\n",
    "shap.decision_plot(base_value=expected_value[1], shap_values=shap_values[1][:1], features=X_train_sel[:1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 分类报告说明\n",
    "多分类中 accuracy=precision ；recall=敏感性（二分类也一样）；\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from pixelmed_calc.custom.components.delong import calc_95_CI\n",
    "from pixelmed_calc.custom.components.metrics import analysis_pred_binary\n",
    "from sklearn.metrics import classification_report,roc_auc_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import random\n",
    "def specificity_per_class(y_true, y_pred, class_label):\n",
    "    conf_matrix = confusion_matrix(y_true, y_pred)\n",
    "    tn = sum(conf_matrix[i, j] for i in range(len(conf_matrix)) if i != class_label for j in range(len(conf_matrix)) if j != class_label)\n",
    "    fp = sum(conf_matrix[i, class_label] for i in range(len(conf_matrix)) if i != class_label)\n",
    "    fn = sum(conf_matrix[class_label, j] for j in range(len(conf_matrix)) if j != class_label)\n",
    "    tp = conf_matrix[class_label, class_label]\n",
    "    specificity = tn / (tn + fp)\n",
    "    ppv = tp / (tp + fp)\n",
    "    npv = tn / (tn + fn)\n",
    "    return specificity,ppv,npv\n",
    "\n",
    "\n",
    "def macro_specificity(y_true, y_pred):\n",
    "  num_classes = len(set(y_true))\n",
    "  \n",
    "  class_specificities = {}\n",
    "  for class_label in range(num_classes):\n",
    "    specificity = specificity_per_class(y_true, y_pred, class_label)\n",
    "    class_specificities[f'Class {class_label}'] = specificity[0]\n",
    "\n",
    "  macro_spec = sum(class_specificities.values()) / len(class_specificities)\n",
    "  \n",
    "  return macro_spec\n",
    "\n",
    "def micro_specificity(y_true, y_pred):\n",
    "  conf_matrix = confusion_matrix(y_true, y_pred)\n",
    "  \n",
    "  fp = conf_matrix.sum(axis=0) - np.diag(conf_matrix) \n",
    "  tn = conf_matrix.sum() - (fp + conf_matrix.sum(axis=1))\n",
    "  \n",
    "  micro_spec = tn.sum() / (tn.sum() + fp.sum())  \n",
    "\n",
    "  return micro_spec\n",
    "\n",
    "def macro_ppv(y_true, y_pred):\n",
    "  num_classes = len(set(y_true))\n",
    "\n",
    "  class_ppvs = {}\n",
    "  for class_label in range(num_classes):\n",
    "    tp = np.diag(confusion_matrix(y_true, y_pred))[class_label]\n",
    "    fp = confusion_matrix(y_true, y_pred)[class_label].sum() - tp\n",
    "\n",
    "    ppv = tp / (tp + fp)\n",
    "    class_ppvs[f'Class {class_label}'] = ppv\n",
    "\n",
    "  macro_ppv = sum(class_ppvs.values()) / len(class_ppvs)\n",
    "\n",
    "  return macro_ppv\n",
    "\n",
    "\n",
    "def macro_npv(y_true, y_pred):\n",
    "  num_classes = len(set(y_true))\n",
    "  \n",
    "  class_npvs = {}\n",
    "  for class_label in range(num_classes):\n",
    "    tn = sum(confusion_matrix(y_true, y_pred)[i, j] for i in range(num_classes) for j in range(num_classes) if i != class_label and j != class_label)\n",
    "    fn = confusion_matrix(y_true, y_pred)[class_label].sum() - np.diag(confusion_matrix(y_true, y_pred))[class_label]\n",
    "\n",
    "    npv = tn / (tn + fn)\n",
    "    class_npvs[f'Class {class_label}'] = npv\n",
    "\n",
    "  macro_npv = sum(class_npvs.values()) / len(class_npvs)\n",
    "  \n",
    "  return macro_npv\n",
    "  \n",
    "\n",
    "def micro_ppv(y_true, y_pred):\n",
    "\n",
    "  conf_matrix = confusion_matrix(y_true, y_pred)\n",
    "\n",
    "  tp = np.diagonal(conf_matrix).sum()\n",
    "  fp = conf_matrix.sum(axis=0) - np.diagonal(conf_matrix)\n",
    "\n",
    "  micro_ppv = tp / (tp + fp.sum())\n",
    "\n",
    "  return micro_ppv\n",
    "\n",
    "\n",
    "def micro_npv(y_true, y_pred):\n",
    "\n",
    "  conf_matrix = confusion_matrix(y_true, y_pred)\n",
    "\n",
    "  tn = conf_matrix.sum() - (conf_matrix.sum(axis=0) + conf_matrix.sum(axis=1) - np.diagonal(conf_matrix).sum())\n",
    "  fn = conf_matrix.sum(axis=1) - np.diagonal(conf_matrix)\n",
    "\n",
    "  micro_npv = tn.sum() / (tn.sum() + fn.sum())\n",
    "\n",
    "  return micro_npv\n",
    "\n",
    "from scipy.stats import norm\n",
    "def AUC_CI(auc, label, alpha = 0.05):\n",
    "\tlabel = np.array(label)#防止label不是array类型\n",
    "\tn1, n2 = np.sum(label == 1), np.sum(label == 0)\n",
    "\tq1 = auc / (2-auc)\n",
    "\tq2 = (2 * auc ** 2) / (1 + auc)\n",
    "\tse = np.sqrt((auc * (1 - auc) + (n1 - 1) * (q1 - auc ** 2) + (n2 -1) * (q2 - auc ** 2)) / (n1 * n2))\n",
    "\tconfidence_level = 1 - alpha\n",
    "\tz_lower, z_upper = norm.interval(confidence_level)\n",
    "\tlowerb, upperb = auc + z_lower * se, auc + z_upper * se\n",
    "\treturn (lowerb, upperb)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "from sklearn.metrics import roc_curve, auc, mean_squared_error\n",
    "\n",
    "\n",
    "\n",
    "def convert2onehot(data, n_classes):\n",
    "    data = np.reshape(data, -1)\n",
    "    onehot_encoder = []\n",
    "    for d in data:\n",
    "        onehot = [0] * n_classes\n",
    "        onehot[d] = 1\n",
    "        onehot_encoder.append(onehot)\n",
    "    return np.array(onehot_encoder)\n",
    "\n",
    "def mac_mic_auc(y_test, y_score, n_classes, include_spec_class: bool = True,\n",
    "                       mapping=None):\n",
    "    \"\"\"\n",
    "\n",
    "    Args:\n",
    "        mapping: label的映射\n",
    "        y_test: 真实标签\n",
    "        y_score: 预测标签\n",
    "        n_classes: 类别数\n",
    "        title: 标题\n",
    "        include_spec_class: 是否包括每个细分标签的ROC曲线。\n",
    "\n",
    "    Returns:\n",
    "\n",
    "    \"\"\"\n",
    "    if mapping is None:\n",
    "        mapping = {}\n",
    "    y_test_binary = convert2onehot(y_test, n_classes=n_classes)\n",
    "    # Compute ROC curve and ROC area for each class\n",
    "    fpr = dict()\n",
    "    tpr = dict()\n",
    "    roc_auc = dict()\n",
    "    # Compute micro-average ROC curve and ROC area\n",
    "    # print(y_test_binary.ravel().shape, y_score.ravel().shape)\n",
    "    fpr[\"micro\"], tpr[\"micro\"], _ = roc_curve(y_test_binary.ravel(), y_score.ravel())\n",
    "    roc_auc[\"micro\"] = auc(fpr[\"micro\"], tpr[\"micro\"])\n",
    "    try:\n",
    "        for i in range(n_classes):\n",
    "            try:\n",
    "                fpr[i], tpr[i], _ = roc_curve(y_test_binary[:, i], y_score[:, i])\n",
    "                roc_auc[i] = auc(fpr[i], tpr[i])\n",
    "            except Exception as e:\n",
    "                logger.error(f'解析{i}类别出错, {e}')\n",
    "        # First aggregate all false positive rates\n",
    "        all_fpr = np.unique(np.concatenate([fpr[i] for i in range(n_classes)]))\n",
    "\n",
    "        # Then interpolate all ROC curves at this points\n",
    "        mean_tpr = np.zeros_like(all_fpr)\n",
    "        for i in range(n_classes):\n",
    "            mean_tpr += np.interp(all_fpr, fpr[i], tpr[i])\n",
    "\n",
    "        # Finally average it and compute AUC\n",
    "        mean_tpr /= n_classes\n",
    "\n",
    "        fpr[\"macro\"] = all_fpr\n",
    "        tpr[\"macro\"] = mean_tpr\n",
    "        roc_auc[\"macro\"] = auc(fpr[\"macro\"], tpr[\"macro\"])\n",
    "    except:\n",
    "        logger.error(f'解析每个类别的ROC出错，大概率是应为数据没有指定类别的样本！')\n",
    "    micro_auc=roc_auc[\"micro\"]\n",
    "    macro_auc=roc_auc[\"macro\"]\n",
    "    return macro_auc,micro_auc\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "num_classes = len(set(y_train_sel[label]))\n",
    "class_specificities_train = {}\n",
    "class_specificities_test = {}\n",
    "class_specificities_val = {}\n",
    "class_specificities_val1 = {}\n",
    "predictions = [[(model.predict(X_train_sel), model.predict(X_test_sel),model.predict(X_val_data),model.predict(X_val1_data))\n",
    "                for model in target] for label, target in zip(labels, targets)]\n",
    "pred_scores = [[(model.predict_proba(X_train_sel), model.predict_proba(X_test_sel),model.predict_proba(X_val_data),model.predict_proba(X_val1_data))\n",
    "                for model in target] for label, target in zip(labels, targets)]\n",
    "\n",
    "for label, prediction, scores in zip(labels, predictions, pred_scores):\n",
    "    for mname, (train_pred, test_pred,val_pred,val1_pred), (train_score, test_score,val_score,val1_score) in zip(model_names, prediction, scores):\n",
    "        # 计算训练集指数\n",
    "        print(f\"{label}-train:\\n\",mname,classification_report(y_train_sel[label], train_pred,digits=5))\n",
    "        for class_label in range(num_classes):\n",
    "            specificity = specificity_per_class(y_train_sel[label], train_pred, class_label)\n",
    "            class_specificities_train[f'Class {class_label}'] = specificity\n",
    "        print(\"Class- Specificities,PPV,NPV:\")\n",
    "        for class_label, specificity in class_specificities_train.items():\n",
    "            print(f\"{class_label}: {specificity}\")\n",
    "        macro_specificity_value=macro_specificity(y_train_sel[label], train_pred)\n",
    "        micro_specificity_value=micro_specificity(y_train_sel[label], train_pred)\n",
    "        macro_ppv_value=macro_ppv(y_train_sel[label], train_pred)\n",
    "        macro_npv_value=macro_npv(y_train_sel[label], train_pred)\n",
    "        micro_ppv_value=micro_ppv(y_train_sel[label], train_pred)\n",
    "        micro_npv_value=micro_npv(y_train_sel[label], train_pred)\n",
    "        print('macro avg:',macro_specificity_value,macro_ppv_value,macro_npv_value)\n",
    "        print('weighted avg:',micro_specificity_value,micro_ppv_value,micro_npv_value)\n",
    "        for i in range(n_classes):\n",
    "              auc_i = roc_auc_score(y_train_sel[label]==i, train_score[:,i]) \n",
    "              print(f'auc{i}:',auc_i,'95%CI',AUC_CI(auc_i, y_train_sel[label]==i, alpha = 0.05))\n",
    "        auc_macro,auc_micro = mac_mic_auc(y_train_sel[label], train_score,n_classes)\n",
    "        print('macro avg_auc:',auc_macro,'95%CI',AUC_CI(auc_macro, y_train_sel[label], alpha = 0.05))\n",
    "        print('micro auc:',auc_micro,'95%CI',AUC_CI(auc_micro, y_train_sel[label], alpha = 0.05))\n",
    "        \n",
    "        # 计算y_test_sel指数\n",
    "        print(f\"{label}-test:\\n\",mname,classification_report(y_test_sel[label], test_pred,digits=5))\n",
    "        for class_label in range(num_classes):\n",
    "            specificity = specificity_per_class(y_test_sel[label], test_pred, class_label)\n",
    "            class_specificities_test[f'Class {class_label}'] = specificity\n",
    "        print(\"Class- Specificities,PPV,NPV::\")\n",
    "        for class_label, specificity in class_specificities_test.items():\n",
    "            print(f\"{class_label}: {specificity}\")\n",
    "        macro_specificity_value=macro_specificity(y_test_sel[label], test_pred)\n",
    "        micro_specificity_value=micro_specificity(y_test_sel[label], test_pred)\n",
    "        macro_ppv_value=macro_ppv(y_test_sel[label], test_pred)\n",
    "        macro_npv_value=macro_npv(y_test_sel[label], test_pred)\n",
    "        micro_ppv_value=micro_ppv(y_test_sel[label], test_pred)\n",
    "        micro_npv_value=micro_npv(y_test_sel[label], test_pred)\n",
    "        print('macro avg:',macro_specificity_value,macro_ppv_value,macro_npv_value)\n",
    "        print('weighted avg:',micro_specificity_value,micro_ppv_value,micro_npv_value)\n",
    "        for i in range(n_classes):\n",
    "              auc_i = roc_auc_score(y_test_sel[label]==i, test_score[:,i]) \n",
    "              print(f'auc{i}:',auc_i,'95%CI',AUC_CI(auc_i, y_test_sel[label]==i, alpha = 0.05))\n",
    "        auc_macro,auc_micro = mac_mic_auc(y_test_sel[label], test_score,n_classes)\n",
    "        print('macro avg_auc:',auc_macro,'95%CI',AUC_CI(auc_macro, y_test_sel[label], alpha = 0.05))\n",
    "        print('micro auc:',auc_micro,'95%CI',AUC_CI(auc_micro, y_test_sel[label], alpha = 0.05))\n",
    "        \n",
    "            \n",
    "        # 计算y_val_data指数\n",
    "        print(f\"{label}-val:\\n\",mname,classification_report(y_val_data[label], val_pred,digits=5))\n",
    "        for class_label in range(num_classes):\n",
    "            specificity = specificity_per_class(y_val_data[label], val_pred, class_label)\n",
    "            class_specificities_val[f'Class {class_label}'] = specificity\n",
    "        print(\"Class- Specificities,PPV,NPV:\")\n",
    "        for class_label, specificity in class_specificities_val.items():\n",
    "            print(f\"{class_label}: {specificity}\")\n",
    "        macro_specificity_value=macro_specificity(y_val_data[label], val_pred)\n",
    "        micro_specificity_value=micro_specificity(y_val_data[label], val_pred)\n",
    "        macro_ppv_value=macro_ppv(y_val_data[label], val_pred)\n",
    "        macro_npv_value=macro_npv(y_val_data[label], val_pred)\n",
    "        micro_ppv_value=micro_ppv(y_val_data[label], val_pred)\n",
    "        micro_npv_value=micro_npv(y_val_data[label], val_pred)\n",
    "        print('macro avg:',macro_specificity_value,macro_ppv_value,macro_npv_value)\n",
    "        print('weighted avg:',micro_specificity_value,micro_ppv_value,micro_npv_value)\n",
    "        for i in range(n_classes):\n",
    "              auc_i = roc_auc_score(y_val_data[label]==i, val_score[:,i]) \n",
    "              print(f'auc{i}:',auc_i,'95%CI',AUC_CI(auc_i, y_val_data[label]==i, alpha = 0.05))\n",
    "        auc_macro,auc_micro = mac_mic_auc(y_val_data[label], val_score,n_classes)\n",
    "        print('macro avg_auc:',auc_macro,'95%CI',AUC_CI(auc_macro, y_val_data[label], alpha = 0.05))\n",
    "        print('micro auc:',auc_micro,'95%CI',AUC_CI(auc_micro, y_val_data[label], alpha = 0.05))\n",
    "        \n",
    "        # 计算y_val1_data指数\n",
    "        print(f\"{label}-val1:\\n\",mname,classification_report(y_val1_data[label], val1_pred,digits=5))\n",
    "        for class_label in range(num_classes):\n",
    "            specificity = specificity_per_class(y_val1_data[label], val1_pred, class_label)\n",
    "            class_specificities_val1[f'Class {class_label}'] = specificity\n",
    "        print(\"Class- Specificities,PPV,NPV:\")\n",
    "        for class_label, specificity in class_specificities_val1.items():\n",
    "            print(f\"{class_label}: {specificity}\")\n",
    "        macro_specificity_value=macro_specificity(y_val1_data[label], val1_pred)\n",
    "        micro_specificity_value=micro_specificity(y_val1_data[label], val1_pred)\n",
    "        macro_ppv_value=macro_ppv(y_val1_data[label], val1_pred)\n",
    "        macro_npv_value=macro_npv(y_val1_data[label], val1_pred)\n",
    "        micro_ppv_value=micro_ppv(y_val1_data[label], val1_pred)\n",
    "        micro_npv_value=micro_npv(y_val1_data[label], val1_pred)\n",
    "        print('macro avg:',macro_specificity_value,macro_ppv_value,macro_npv_value)\n",
    "        print('weighted avg:',micro_specificity_value,micro_ppv_value,micro_npv_value)\n",
    "        for i in range(n_classes):\n",
    "              auc_i = roc_auc_score(y_val1_data[label]==i, val1_score[:,i]) \n",
    "              print(f'auc{i}:',auc_i,'95%CI',AUC_CI(auc_i, y_val1_data[label]==i, alpha = 0.05))\n",
    "        auc_macro,auc_micro = mac_mic_auc(y_val1_data[label], val1_score,n_classes)\n",
    "        print('macro avg_auc:',auc_macro,'95%CI',AUC_CI(auc_macro, y_val1_data[label], alpha = 0.05))\n",
    "        print('micro auc:',auc_micro,'95%CI',AUC_CI(auc_micro, y_val1_data[label], alpha = 0.05))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 绘制概率柱状图和折线图曲线"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-10T23:59:22.377005Z",
     "start_time": "2023-07-10T23:59:21.416149Z"
    }
   },
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "plt.figure(figsize=(10, 10))\n",
    "plt.subplot(211)\n",
    "sns.barplot(x='model_name', y='Accuracy', data=metric, hue='Task')\n",
    "plt.subplot(212)\n",
    "sns.lineplot(x='model_name', y='Accuracy', data=metric, hue='Task')\n",
    "plt.savefig(f'img/Rad_model_acc.svg', bbox_inches = 'tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 绘制ROC曲线-train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_names = list(models.keys())\n",
    "sel_model = model_names\n",
    "\n",
    "for sm in sel_model:\n",
    "    if sm in model_names:\n",
    "        sel_model_idx = model_names.index(sm)\n",
    "        # Plot all ROC curves\n",
    "        plt.figure(figsize=(8, 8))\n",
    "        for pred_score, label in zip(pred_scores, labels):\n",
    "            okcomp.comp1.draw_roc_per_class(np.array(y_train_sel[label]), pred_score[sel_model_idx][0], n_classes=n_classes,\n",
    "                                            include_spec_class=True, title=f\"Model: {sm}\")\n",
    "            plt.savefig(f'img/model_{sm}_test_roc.svg', bbox_inches = 'tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 绘制ROC曲线-test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-11T00:01:20.363376Z",
     "start_time": "2023-07-11T00:01:16.019092Z"
    }
   },
   "outputs": [],
   "source": [
    "sel_model = model_names\n",
    "\n",
    "for sm in sel_model:\n",
    "    if sm in model_names:\n",
    "        sel_model_idx = model_names.index(sm)\n",
    "        # Plot all ROC curves\n",
    "        plt.figure(figsize=(8, 8))\n",
    "        for pred_score, label in zip(pred_scores, labels):\n",
    "            okcomp.comp1.draw_roc_per_class(np.array(y_test_sel[label]), pred_score[sel_model_idx][1], n_classes=n_classes,\n",
    "                                            include_spec_class=True, title=f\"Model: {sm}\")\n",
    "            plt.savefig(f'img/model_{sm}_test_roc.svg', bbox_inches = 'tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 绘制ROC曲线-val\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sel_model = model_names\n",
    "\n",
    "for sm in sel_model:\n",
    "    if sm in model_names:\n",
    "        sel_model_idx = model_names.index(sm)\n",
    "        # Plot all ROC curves\n",
    "        plt.figure(figsize=(8, 8))\n",
    "        for pred_score, label in zip(pred_scores, labels):\n",
    "            okcomp.comp1.draw_roc_per_class(np.array(y_val_data[label]), pred_score[sel_model_idx][2], n_classes=n_classes,\n",
    "                                            include_spec_class=True, title=f\"Model: {sm}\")\n",
    "            plt.savefig(f'img/model_{sm}_val_roc.svg', bbox_inches = 'tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 绘制ROC曲线-val1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sel_model = model_names\n",
    "\n",
    "for sm in sel_model:\n",
    "    if sm in model_names:\n",
    "        sel_model_idx = model_names.index(sm)\n",
    "        # Plot all ROC curves\n",
    "        plt.figure(figsize=(8, 8))\n",
    "        for pred_score, label in zip(pred_scores, labels):\n",
    "            okcomp.comp1.draw_roc_per_class(np.array(y_val1_data[label]), pred_score[sel_model_idx][3], n_classes=n_classes,\n",
    "                                            include_spec_class=True, title=f\"Model: {sm}\")\n",
    "            plt.savefig(f'img/model_{sm}_val1_roc.svg', bbox_inches = 'tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-11T00:08:45.718777Z",
     "start_time": "2023-07-11T00:08:42.366765Z"
    }
   },
   "source": [
    "# 混淆矩阵"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-11T00:07:15.801312Z",
     "start_time": "2023-07-11T00:07:10.742970Z"
    }
   },
   "outputs": [],
   "source": [
    "# 设置绘制参数\n",
    "sel_model = model_names\n",
    "c_matrix = {}\n",
    "\n",
    "for sm in sel_model:\n",
    "    if sm in model_names:\n",
    "        sel_model_idx = model_names.index(sm)\n",
    "        for idx, label in enumerate(labels):\n",
    "            cm = okcomp.comp1.calc_confusion_matrix(predictions[idx][sel_model_idx][-1], y_test_sel[label], num_classes=n_classes)\n",
    "            c_matrix[label] = cm\n",
    "            plt.figure(figsize=(5, 4))\n",
    "            plt.title(f'Model:{sm}')\n",
    "            okcomp.comp1.draw_matrix(cm, norm=False, annot=True, cmap='Blues', fmt='.3g')\n",
    "            plt.savefig(f'img/model_{sm}_cm.svg', bbox_inches = 'tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 保存模型结果\n",
    "可以把模型预测的标签结果以及每个类别的概率都保存下来。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "\n",
    "sel_model = model_names\n",
    "os.makedirs('results', exist_ok=True)\n",
    "for idx, label in enumerate(labels):\n",
    "    for sm in sel_model:\n",
    "        if sm in model_names:\n",
    "            sel_model_idx = model_names.index(sm)\n",
    "            target = targets[idx][sel_model_idx]\n",
    "            # 预测训练集和测试集数据。\n",
    "            train_indexes = np.reshape(np.array(ids.loc[list(X_train_sel.index)]), (-1, 1)).astype(str)\n",
    "            test_indexes = np.reshape(np.array(ids.loc[list(X_test_sel.index)]), (-1, 1)).astype(str)\n",
    "            y_train_pred_scores = target.predict_proba(X_train_sel)\n",
    "            y_test_pred_scores = target.predict_proba(X_test_sel)\n",
    "            columns = ['ID'] + [f\"{label}-{i}\"for i in range(y_test_pred_scores.shape[1])]\n",
    "            # 保存预测的训练集和测试集结果\n",
    "            result_train = pd.DataFrame(np.concatenate([train_indexes, y_train_pred_scores], axis=1), columns=columns)\n",
    "            result_train.to_csv(f'./results/{sm}_train.csv', index=False)\n",
    "            result_test = pd.DataFrame(np.concatenate([test_indexes, y_test_pred_scores], axis=1), columns=columns)\n",
    "            result_test.to_csv(f'./results/{sm}_test.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
